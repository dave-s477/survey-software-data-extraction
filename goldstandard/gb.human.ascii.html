<html><body link="black" alink="black" vlink="black" hlink="black">
<b>PMC2246299</b><br>
Phylogenetic simulation of promoter evolution: estimation and modeling of binding site turnover events and assessment of their impact on alignment tools<br>
Phylogenetic simulation of promoter evolution were used to analyze functional site turnover in regulatory sequences.<br>
<br>
Background<br>
Transcription regulation is a central component in the control of gene expression. Identification of functional cis-elements in promoter regions, a key to understanding gene regulation, has turned out to be a difficult task thus far. With the increasing availability of genome sequences, phylogenetic footprinting appeared to offer a very promising approach for identifying cis-elements [1,2]. One essential assumption of phylogenetic footprinting is sequence conservation of functionally homologous genes. While such an assumption has been frequently found to be true for protein encoding sequences, there is no straightforward relationship of conservation between sequence and function for non-protein-coding regulatory sequences [3,4].<br>
Compared to protein-coding regions, transcriptional promoter regions are subject to much less stringent selection and have higher nucleotide substitution rates, where short transcription factor binding sites can easily turn over and be replaced by new ones arising from random mutations [5,6]. In many cases, the function of a regulatory sequence may, however, remain well conserved despite substantial sequence changes. One of the best-studied examples is the even-skipped enhancer system S2E of Drosophila species, which is highly conserved at the functional level (for example, maintaining a high similarity of expression pattern) but substantially diverged at the sequence level. Such sequence divergence includes large insertions and deletions between different sites, substitutions within sites, and gains and losses of sites. Several experimental studies suggested that compensatory mutations in the even-skipped enhancer region are the key to maintain the functionality of the enhancer in evolution [7-9]. Estimates of transcription factor binding site (TFBS) turnover rates rank as high as 32-40% between human and rodent species [6], and can also happen at transcription start sites (TSSs) of orthologous genes [10], albeit at a lower frequency. The phenomenon of TFBS turnovers in regulatory regions suggest that any phylogenetic footprinting methods based on a simple trace of the evolution of nucleotides can be highly effective in some cases, but are unlikely to be able to identify all functionally important elements in regulatory genomic sequences, particularly in distantly related species. In this sense, a major improvement in TFBS identification will rely on a better understanding of evolutionary mechanisms regarding TFBS turnover events.<br>
While TFBS turnover has been known for a long time, it has not become a widely studied topic until recently, when the availability of related genome sequences made it amenable to systematic studies [11-13]. With our currently limited knowledge about their structure and functional constraints, it is much more challenging to study the evolution of regulatory sequences than of protein-coding sequences. Most published experimental studies have been conducted on a gene-by-gene and element-by-element basis, and computational studies on real data are severely limited by the available functional site mapping data. In the absence of real biological data, computational simulation may provide the best way to study TFBS evolution and turnover in a systematic way. A pioneering simulation of TFBS evolution estimated the expected time for new binding sites to arise from point mutations in promoter regions, where binding sites were represented by simple consensus sequences, and promoters were evolved under a neutral evolution model [5]. A recent study examined the expected time for a new site to evolve and become fixed in a population by positive selection, where the authors considered effective population size and used position weight matrices (PWMs) to model TFBSs [14]. The study found that the existence and location of pre-sites of functional sites could be major factors determining the expected time and location of newly evolved sites, while the relative position of sites had little impact on the final location of new functional sites.<br>
The above simulation studies explicitly assume that the functions encoded in regulatory regions evolve and change with the change in sequences. There are, however, many cases like the evolution of the even-skipped enhancer mentioned above, in which the regulatory sequence changes but functions (that is, the resulting expression patterns) appear unchanged. Frequently, such genes are involved in crucial developmental processes and, therefore, subject to stringent functional constraints [15-18]. Our study thus investigates how a promoter evolves under the neutral scenario of functional maintenance in 'status quo', that is, with little or no change in the presence and strength of functional elements. Specifically, we address the expected replacement turnover rate (RTR) of TFBSs in promoter sequences in relation to evolutionary distance, insertion/deletion (InDel) rate, and restricted translocation distance of TFBSs. In accordance with previous work, our study suggests that replacement turnover of TFBSs can happen quickly in evolution and varies significantly among different TFBSs, but can be predicted using simple mathematical models.<br>
TFBS turnover phenomena in promoter sequences raise the important question about the ability of current multiple sequence alignment (MSA) tools to identify TFBSs in comparative genomics studies. Comparative evaluations of alignment tools have been conducted previously, but usually in conjunction with a newly developed tool [19-22] and with only few attempts at a comprehensive or systematic evaluation of different tools [23-26]. However, little has been done regarding a performance evaluation of MSA tools for the task of aligning non-coding genomic sequences, largely due to lack of good benchmark datasets of real sequences. As a result, tool performance assessment on genomic sequences was often based on indirect measures, such as an alignment of putative conserved non-coding regions, functional sites [21], or exon regions [27].<br>
Simulation provides an effective way to circumvent the problem of lack of data. Simulation data generated in silico make it possible to evaluate tool performance on direct measures of alignment accuracy. For example, a careful work on tool benchmarking was based on simulated Drosophila non-coding sequences, in which the authors compared the accuracy, sensitivity and specificity of several tools for pair-wise alignment [28]. A recent simulation study by the same group examined the limitations of several MSA tools for TFBS identification and divergence distance estimation in aligning non-coding sequences, where TFBSs may be gained or lost in neutral evolution [29]. However, these evaluation studies implicitly assumed a strong correlation between conservation at the functional and sequence level, and assessed tools on their ability to align homologous base pairs, that is, the alignment accuracy of bases evolved from the same site in the common ancestral sequences. Different from protein coding sequences, however, many recent studies of non-coding sequence evolution suggest that frequently there is only a weak correlation between conservation at the functional level and sequence level among non-coding orthologous sequences [1,3,6-8,10] (see Figure 1 for an example of homology at the functional level and sequence level).<br>
Uncovering TFBSs in promoter sequences by cross-species comparison has so far been successful in some cases, but most approaches rely on alignments that are pre-computed on the whole genome. It is an open issue how appropriate these strategies are for non-coding alignments. Taking advantage of our <software>Phylogenetic Simulation of Promoter Evolution</software> (<software>PSPE</software>) simulation tool, we assess the performance of commonly used MSA algorithms for aligning TFBS in orthologous promoter sequences, where the function of a promoter (that is, an ensemble of binding sites under constraints) is maintained, but TFBS replacement turnovers are allowed to occur. Different from previous studies that assessed tool performance with respect to their ability to align homologous bases, we thus focus on assessing tool performance by their ability to align functional sites that are homologous at the functional level but may not be homologous at the sequence level. To our knowledge, no such assessment of MSA tool performance from the viewpoint of functional homology, that is, alignment of functional elements in the presence of re-arrangements and turnovers, has been carried out. Our findings can thus serve as useful references for alignment tool selection in comparative genomics and provide insights for the improvement of non-coding multiple sequence alignment.<br>
<br>
Results<br>
Simulation system<br>
We designed a new computational system, <software>PSPE</software>, specifically to perform simulations of regulatory sequence evolution, such as promoter sequences. Different from other programs for sequence evolution simulation, which frequently use different evolutionary models for functional and non-functional sites, <software>PSPE</software> imposes a variety of functional constraints and validates at discrete intervals that these constraints are maintained. Such functional constraints include GC content, presence and strength of functional sites, location and copy number restrictions on functional sites, and space constraints between different functional sites. Depending on the specification of these constraints, turnover events are thus possible, as functional sites are not generally tied to a specific location in the sequence.<br>
<software>PSPE</software> reads a set of simulation parameters from a single configuration file (Figure 2). The root sequence for simulation can be provided by the user or generated by <software>PSPE</software>, according to user-specified length, a background Markov model, and functional constraints. <software>PSPE</software> can generate different random evolutionary trees by simulating evolution distances (branch length) with an exponential model, and the number of descendent sequences (number of branches from a parent node) by a Poisson process. While binary trees are commonly used in phylogenetic studies, <software>PSPE</software> can generate different tree structures with either a fixed or a random number of branches from the root or internal node. Given a phylogenetic tree and a sequence at its root, <software>PSPE</software> can use one of many commonly used DNA substitution models as well as different InDel models to simulate sequence evolution, subject to defined functional constraints, such as GC content, functional site locations and interactions of functional sites. By default, <software>PSPE</software> reports the alignment of the simulated sequences, as well as the sequences themselves and the locations of functional sites in each sequence. <software>PSPE</software> also has the capability to simulate replicates from the same tree and same root sequence, which is essential for quantitative evolution simulations.<br>
<br>
TFBS replacement turnover rate estimation<br>
In this study, a functional TFBS in a descendent sequence corresponds to the original TFBS if its sequence can be traced back to the TFBS sequence in the ancestor; otherwise, the TFBS is regarded as a new one. A TFBS replacement event is therefore defined as an event in which an original TFBS is replaced by a new TFBS of the same type through any two or more events (destruction of the old site and creation of the new one), including point mutations, insertions and deletions. The RTR is defined as the probability of a functional TFBS in an ancestral sequence to be replaced by a newly evolved one in the descendent sequence. We estimate TFBS RTR as the proportion of descendent sequences in which the TFBS is replaced at least once in the evolution process from an ancestral sequence. For example, assuming that we simulate M different descendent sequences from the same ancestral sequence, and we observe replacement turnover of the TFBS in m descendent sequences, then the estimate of RTR is m/M. In the following, we report the mean RTR averaged over different ancestor sequences, that is:<br>
RT^R=1K?i=1KmiMi<br>
where K is the number of different ancestral sequences, Mi is the number of all descendent sequences of the ith ancestral sequence, and mi is the number of descendent sequences in which the TFBSs of interest have been subjected to replacement turnover. We also report the median values, as the distributions of RTRs are not necessarily approximate to the normal distribution.<br>
Using <software>PSPE</software> for sequence evolution simulation, we are able to study the replacement turnover rate of functional conserved TFBSs in the evolution process of promoter sequences. In a complicated evolution process, many different events can occur at a TFBS, including point mutation, deletion, insertion, translocation, duplication and replacement. Our study here focuses only on TFBS replacement turnover in a simple 'status quo' scenario, assuming that all TFBSs in the sequences are essential to maintain proper gene expression levels and are thus functionally conserved in all descendent sequences. All functionally conserved TFBS are, however, allowed to be translocated to neighboring regions or replaced by newly evolved sites within a given restricted space. As ancestral sequences, we use either real or simulated human promoter sequences.<br>
As the main transcription factor for this study, we used the well-known cell-cycle regulator E2F, and investigated two additional factors, Myc and NF?B, to validate our model for estimating TFBS replacement rates. Both E2F and Myc are important transcription regulators of cell cycle progression, DNA replication, and apoptosis [30-33]. In some cases, E2F and Myc form a complex to regulate gene expression in a combinatorial fashion [34,35]. NF?B is a family of ubiquitously expressed transcription factors involved in both the onset and the resolution of inflammation. NF?B is also widely believed to govern the expression of many genes for stress response, intercellular communications, cellular proliferation and apoptosis [36-38]. To simulate ancestral sequences containing binding sites of these transcription factors, we used their positional weight matrix models in the <database>JASPAR</database> database [39]. Binding sites in real human promoters known to be regulated by E2F were based on computational prediction (see Materials and methods). The simulated background promoter sequences were generated from a third order Markov model trained on 25,088 annotated human promoter sequences. We used the HKY85 model [40] to simulate nucleotide substitution, a geometric distribution for the size of sequence InDel events, and a gamma distribution and invariant rate (?+I) for modeling heterogeneity of substitution rates. The HKY85 model does not assume equal base frequencies and can account for the difference between transitions and transversions with one parameter. Sequence evolution was then additionally subject to diverse functional constraints related to the specific characteristics of transcriptional regulatory regions (Table 1). While many different factors may have significant impact on the RTR of a TFBS, we mainly focused on three important and interesting factors: evolution divergence distance, InDel rate, and restricted translocation distance.<br>
<br>
Evolution of individual binding sites<br>
We first studied the effect of divergence distance on the RTR of E2F sites (Figure 3). With increasing evolutionary divergence, we expect the RTR of a TFBS to increase, so the question is how fast and in what pattern the RTR increases along with the divergence distance. To answer this question, we estimated the RTR of a TFBS within a new descendent sequence, evolved from an ancestral sequence at 15 different divergent distances from 0.01 to 5.0, measured by the number of substitutions per site (see Materials and methods). At each of the different distances, we simulated 1,000 ancestor sequences and 1,000 descendent sequences from each ancestral sequence. In the simulation, E2F binding sites in ancestral and descendent sequences were subject to the same functional constraints (Figure 3), such that each simulated sequence had one and only one functional E2F site. As a consequence, E2F replacement could occur only at the time when the loss of the original functional site was accompanied by the creation of a new functional site. This requirement is likely to lead to conservative estimates of turnover rates.<br>
Initial results showed that the RTR of E2F significantly increased as the divergence distance increased (Figure 4a). The change of RTR was faster at short divergence distances (number of substitutions per site &lt;1) than at large divergence distances (number of substitutions per site &gt;3). Based on the assumption that the number of E2F replacement events during any evolution time interval follows a Poisson distribution, we further analyzed the relationship between RTR and sequence divergence distance. Assuming that replacement turnover events occur at a Poisson rate ?, the probability of no replacement in a time interval t measured by number of substitutions per site is:<br>
Pr?(N=0)=e??t(?t)00!=e??t<br>
Therefore, the probability of at least one replacement turnover, or expected RTR, of a TFBS in a time interval t is:<br>
RTR = Pr(N ? 1) = 1 - Pr(N = 0) = 1 - e-?t<br>
which corresponds to the cumulative density function of an exponential distribution with mean 1/?.<br>
We fitted the observed E2F RTR data with this exponential model and estimated the model parameter ?. This simple exponential model fitted well with the RTR of E2F observed in our simulation (Figure 4a), where the model parameter ? was 0.0832 and 0.0724 for fitting the mean and median of the observed RTR, respectively. In other words, the average probability for a replacement turnover event of an E2F binding site was 8.3% at a divergence distance of one substitution per site, suggesting the potential of substantial E2F turnover.<br>
To verify the RTR of E2F estimated on simulated promoter sequences, we repeated the experiment using real promoter sequences of human genes as ancestral sequences, known to be under E2F regulation from wet-lab experiments [41,42]. Among 127 E2F regulated genes confirmed by ChIP-chip experiments [42], we were able to select 11 genes, each having one and only one E2F binding site in the upstream region of 500 base pairs (bp) from its transcription start site (see Materials and methods; see Additional data file 1 for details of the 11 genes). Most of the 11 genes are well known to be under regulation of E2F, especially CDC6, for which the location of the E2F binding site and functional activity of E2F have been characterized [43-45]. Real promoter sequences would presumably give us a more realistic estimate of RTR of E2F sites than starting from simulated background sequences. One such potential difference is that real promoter sequences may contain remnants or 'ghosts' of previously functional binding sites accumulated during evolution, which could become functional again by a small number of sequence changes, which would thus result in higher turnover rates.<br>
Starting with the real promoter sequences, we ran essentially the same simulation as the simulated promoter sequences above (Table 1), with the minor difference of using a different restricted location of E2F sites for each promoter, as the actual E2F locations were different. We kept, however, the same restricted distance for translocation of E2F sites as those in simulated promoter sequence (50 bp centered on the ancestral site). Since we had a limited number of real promoters, we simulated 10,000 descendent sequences from each ancestral promoter instead of 1,000 descendents as above. The RTRs of E2F sites estimated in this way were highly consistent with those using simulated ancestral sequences across different divergence distances. As a result, the exponential model given in equation 2 fitted well with the observed RTRs (Figure 4b), where the model parameter ? was 0.0833 and 0.0755 for fitting mean and median values, respectively. Both ? values were indeed slightly higher than the corresponding ones starting from simulated ancestral sequences (Table 2), but such small differences may easily be caused by other factors (for example, different locations of E2F sites).<br>
To validate the good fit of estimated turnover rates with a simple exponential model, we performed similar independent simulation studies for the additional TFBSs of Myc and NF?B. Both Myc and NF?B have palindromic binding sites with a length of 11 and 10 bases, respectively. Myc sites have more conserved positions in the center region, consisting of mixed A/T and G/C nucleotides, whereas NF?B has highly conserved positions at the two sides, consisting of mostly G/C nucleotides (Figure 3). Overall, Myc sites are the most degenerate among the three TFBSs. These differences in information content and sequence composition may lead to different RTRs. It was instructive to see how these factors affected the RTR, and whether the exponential model provided as good a fit for these other TFBS as well. For each TFBS, we again simulated 1,000 ancestral promoter sequences, and for each ancestral promoter sequence, we simulated 1,000 descendent sequences at each of 15 divergence distances as above. We also used the same substitution and InDel models for the sequence evolution (Table 1). For the purpose of comparison, we imposed the same location and copy number constraints on both TFBSs as specified in Figure 3.<br>
Our results indicated that the RTR of Myc was consistently more than two times higher than that of NF?B across all divergence distances (Figure 5 and Table 2) For example, the observed RTRs for Myc and NF?B were 0.219 and 0.083 at a divergence distance of 1.0, and 0.373 and 0.167 at a divergence distance of 2.0. These results suggested that differences in sequence composition had a significant impact on the RTRs of a TFBS. In this case, the sequence composition of the NF?B site, which is G/C rich at the two sides and A/T rich in the center, is more different from the background than that of Myc, for which A/T and G/C positions are almost uniformly distributed. Fitting the RTR data with our exponential model, we observed again a good fit for both TFBSs (see Table 2 for the estimated model parameters ?).<br>
<br>
Turnover rates of regulatory modules: the Myc-E2F pair<br>
Both Myc and E2F are important transcription factors in coordinating cell-cycle regulation, and partner together to regulate some common target genes [34,35]. As a restricted space between two TFBSs, that is, to enable an effective interaction, can limit the replacement turnover of each individual TFBS, we were interested in assessing how two sites can evolve together as a regulatory module. We studied the RTR of the Myc-E2F pair in a simple scenario in which there was one and only one pair of Myc-E2F in a promoter sequence. For both E2F and Myc, we kept the location restriction relative to the TSS identical to the above studies on single sites, and studied their RTRs by simulations with and without a constraint of restricted space between them (Table 3). We performed simulations at different divergence distances as for individual sites above.<br>
We calculated the observed RTRs of the Myc-E2F pair from the simulated sequences, and compared them to the expected ones assuming independent evolution of both sites. The expected RTR of both sites, defined as the probability of observing simultaneous replacement turnovers of both Myc and E2F, was estimated as the product of the individual RTRs from the simulation of single sites. The expected RTR of a single site, defined as the probability of observing a replacement turnover in only one site of the pair, was estimated from the above simulation of individual sites. Results showed that the expected RTRs were close to the observed ones in simulations without an additional space constraint between two TFBSs (Figure 6a,b), validating the independent evolution of both sites. For the simulation with additional space constraints between the pair, the observed RTRs of both sites showed significant deviation from the predicted ones assuming independent evolution, although the expected and observed RTRs of single sites were still close (Figure 6d). The significantly lower RTRs of both sites indicate that the space constraint between two sites made it less likely for them to turn over simultaneously (Figure 6c).<br>
The small difference between the observed RTRs of the Myc-E2F pair and the expected ones assuming independence of individual TFBSs suggested that it was reasonable to describe the independent evolution of two sites within a simple predictive model. Based on this assumption, we thus described the RTR of a given TFBS pair by:<br>
RTRpair=(1?e??1t)?(1?e??2t)<br>
where ?1 and ?2 are the expected Poisson rates of replacement turnover events for TFBS 1 (E2F) and TFBS 2 (Myc). Similarly, the probability of a replacement turnover of one and only one of two TFBSs can be modeled by:<br>
RTRone_in_pair=(1?e??1t)?e??2t+e??1t?(1?e??2t)<br>
We fitted the observed RTR data with both models 3 and 4. Both models fitted well with data as shown in Figure 6a,b,d, validating our assumption for the independent evolution of TFBSs. However, as the RTRs for the Myc-E2F pair in Figure 6c show, the simple models began to deviate from the simulations in more complex scenarios including dependencies between sites.<br>
<br>
TFBS conservation between human and mouse<br>
Because of the moderate divergence distance between mammalian genomes, such as those of human and mouse, there is a strong interest in comparative studies of their genomes as an important way to infer gene function and gene regulation as well as their evolutionary mechanisms. While it is relatively easy to compare the coding sequences of human and mouse orthologous genes, it remains a difficult task to compare their promoter sequences, largely because they are more divergent than coding sequences. One pioneering comparative genomics study estimated that a fraction as high as 32-40% of the human functional TFBSs may not be functional in rodents, suggesting a high turnover rate of TFBSs [6]. A recent study estimated that the divergence distances of human and mouse from the last common ancestor are 0.1187 and 0.3987 substitutions per site, respectively [46]. Another study estimated the total divergence distance of human and mouse at about 0.8 substitutions per site [47]. Based on these two estimates, we here set the divergence distances of human and mouse from their last common ancestor to be 0.2 and 0.6, respectively, in terms of the number of substitutions per site in neutrally evolving regions. In this study, we simulated TFBS evolution of human and mouse from their last common ancestral species in the hope of shedding some light on the evolution of their TFBSs. Using the same three TFBSs as above, we estimated RTRs of individual TFBSs in human and mouse orthologous sequences at different InDel rates as well as at different restricted translocation distances.<br>
Effect of InDel rate variation<br>
We again simulated 1,000 ancestral promoter sequences and evolved 1,000 pairs of human and mouse descendent sequences from each ancestral sequence, but this time varying the ratio of InDel to substitution rate from 0 (that is, no InDels at all) to 0.2 (one InDel per five substitution events) at ten different steps. Except for the InDel rate, we used the same models and parameters as given in Table 1. We performed three independent simulations for the TFBSs of E2F, Myc and NF?B. The evolution of individual TFBSs was under the same functional constraints as above (Figure 3).<br>
Instead of calculating the TFBS RTRs from their common ancestral sequences, we estimated the probability of observing replacement turnovers of individual TFBSs in at least one species, which we defined as the RTR between human and mouse. We found that at zero or very low InDel rates, the RTRs of Myc and NF?B between human and mouse were almost zero, whereas E2F had a low RTR (Figure 7). As expected, RTRs of all TFBSs increased as the InDel rate increased. The RTR of NF?B, however, was almost one magnitude smaller than that of either E2F or Myc, indicating a significant effect of the nucleotide composition of different TFBSs. Our analysis suggested that the TFBS RTR between human and mouse could be approximated by an exponential function of the InDel rate given by:<br>
Rate = -a + b ? e1.5?<br>
where a and b are parameters, and ? is the InDel rate. Therefore, at a zero InDel rate (? = 0), the base RTR is (b - a), which cannot be less than the zero, implying that b must be larger or equal to a. We found that this model fitted well with the RTR data of all three TFBSs regardless of using the mean or median value of the RTR (Figure 7). Estimates of model parameters for the individual TFBSs are given in Table 4.<br>
<br>
Influence of restricted translocation distance<br>
TFBS often have a preferred location relative to the TSS, but many TFBSs can move within a limited distance while maintaining their regulatory function. Such a restricted translocation distance relative to the TSS may have an important impact on TFBS evolution. In a final simulation, we studied how the RTR of a TFBS between human and mouse was affected by its restricted translocation distance.<br>
We simulated TFBS evolution under 10 different restricted distances of translocation ranging from 0 to 300 bp from the original location of a TFBS in ancestral sequences, where we set 20 bp as the minimum distance of a TFBS to TSS. For each maximal translocation distance, we simulated 1,000 ancestral promoter sequences and 1,000 pairs of descendent human and mouse sequences from each ancestral sequence using the models given in Table 1. We performed a separate simulation for the same three TFBSs, and estimated the RTR between human and mouse as defined above. The RTR between human and mouse increased approximately linearly with the size of the restricted translocation range (Figure 8). The means of the RTR could therefore be fitted well with a linear model given by:<br>
RTR=a+c1??c2?=a+c?<br>
where a, c1, c2 and c are model parameters, c is the product of c1 and c2, and ? is the restriction translocation distance of a TFBS. In this model, c1 and c2 are associated with the evolutionary distances of species one and two from their last common ancestral species. Therefore, the TFBS RTR in a single species is a linear function of the square root of its restricted translocation distance. Interestingly, while the median RTRs for E2F could also be fitted quite well with this model (Figure 6a), the fit for Myc and NF?B was less good, hinting at the strong effects that different motifs can have on some of the promoter features studied here.<br>
<br>
Impact of transition/transversion ratio<br>
To better simulate sequences of closely related species, which generally have a higher ratio between transition and transversion substitution rates than distantly related species, we used a relatively large ratio of transition to transversion (20:1) in all the above simulations. This large ratio made sense in our case, as we simulated sequence evolution in a stepwise fashion with a small divergence distance (0.05 substitutions per site) at each step. To check whether a large change in transition to transversion ratio would have significant impact on RTRs, we also ran all the above simulations at a much smaller ratio of 4:1. We used the Wilcoxon rank sum test to check whether the difference between the means of the resulting RTRs was significantly different from zero (data not shown). We found no statistically significant differences in our results (Bonferroni-corrected significance level of P ? 0.05). The results suggested that our observed replacement turnovers were slow processes relative to nucleotide substitutions.<br>
<br>
<br>
Evaluation of alignment tools<br>
In addition to the theoretical studies regarding turnover rates, the <software>PSPE</software> simulator can be used to assess the impact of the turnover phenomenon on practical applications in comparative genomics. In the following, we looked specifically at the problem of identifying functional binding sites in multiple sequence alignments. Most current alignment tools are based on the assumption that the functional sites in orthologous sequences are homologous in sequence space, that is, that they can be traced back to the same position in the ancestral genome. Replacement turnover events of functional sites in promoter sequences, however, make this assumption somewhat unrealistic, which could consequently limit the performance of a tool for aligning non-coding sequences. Our evaluation aimed to: compare different multiple sequence alignment tools for their robustness to violation of this assumption; and investigate the impact of increasing the number of species on tool performance.<br>
We evaluated a set of representative MSA tools for their performance in detecting TFBSs in several sets of orthologous sequences, generated from an underlying phylogenetic tree of five mammalian genomes (Figure 9). The rationale for using the mammalian tree topology was to achieve a realistic assessment of TFBS detection accuracy and to allow for a fair comparison between different tools. First, in most comparative genomics studies, species in comparison often have different divergence distances from their last common ancestor. Second, it is also frequently assumed that an MSA tool should work better when aligning more closely related species at the beginning stage and adding more distantly related species in later stages, especially for those based on a progressive approach. We used evolutionary distances that were recently inferred from coding regions [46], but evaluated the tree at different scale factors as it is not generally known how well these distances reflect the actual substitution rates in non-coding regions. We extended the simulation to large divergence distances to test the notion that conserved sites should be readily picked up when the surrounding sequence has sufficiently diverged. To assess the validity of our observations, we consistently evaluated tool performance with additional benchmark datasets, generated from a phylogenetic tree with a star topology in which all descendent sequences had the same evolutionary distance from their last common ancestral sequence. The evaluation results are consistent with those reported below (see Additional data file 2 for details).<br>
We scaled the mammalian phylogenetic tree at eight different levels from 0.25 to 5, relative to the actual distances, and generated a benchmark promoter dataset at each scale level (defined as divergence scale coefficient), where each dataset contained 1,000 replicates of orthologous promoter sequences of the five species. Sequences were simulated under the HKY85 nucleotide substitution model with gamma and invariant rate (?+I) for modeling substitution rate heterogeneity (Table 5). In the dataset, each sequence contained exactly one functional binding site for each of the six transcription factors: Pax6, TP53, IRF2, PPARG, ROAZ, and YY1E2F. YY1E2F is a composite TFBS consisting of YY1 and E2F binding sites that reportedly interact with each other in cell cycle gene regulation [48]. Binding sites were subject to a set of functional constraints (Table 6) that were set to allow for turnover within a restricted distance, but keeping the overall order of the binding sites unchanged. Simulation allowed us to quantify the amount of turnover: how many non-aligned functional sites were due to turnover compared to 'simple' misalignments, and whether some tools would in fact be able to align functional sites despite turnover.<br>
We used this dataset to assess the performance of five widely used MSA tools: <software>CLUSTALW</software> [49], <software>DIALIGN</software> [50], <software>AVID</software>/<software>MAVID</software> [19,51], <software>LAGAN</software>/<software>MLAGAN</software> [27], and <software>MUSCLE</software> [20]. Among the five tools, <software>AVID</software>/<software>MAVID</software> is the fastest alignment tool and uses exactly matching words as alignment seeds to speed up the alignment process, albeit at the expense of lower alignment accuracy. As an improvement, both <software>DIALIGN</software> and <software>LAGAN</software>/<software>MLAGAN</software> adopt non-exact word matching for finding alignment seeds, which can improve their ability to detect degenerate functional sites. <software>DIALIGN</software> identifies alignment seeds by finding consistent sequence segments of a fixed length between sequences, while <software>LAGAN</software>/<software>MLAGAN</software> locates alignment seeds by chaining together neighboring similar words. Both <software>CLUSTALW</software> and <software>MUSCLE</software> are primarily based on the dynamic programming algorithm. <software>MUSCLE</software>, however, has made significant improvements over <software>CLUSTALW</software> by employing anchoring techniques and a progressive refinement approach. The performance was measured as TFBS detection accuracy, defined as the proportion of nucleotides in functionally homologous TFBSs that were correctly aligned. The detection accuracy reported here is the average value over 1,000 replicates at each divergence scale level.<br>
For the two species (human and baboon) alignment, all five tools showed high detection accuracies of TFBS with no significant difference between each other (Figure 10a(1)). When adding more distant species, such as mouse, to the alignment, we found that TFBS detection accuracies of all tools were dramatically decreased, especially those of <software>MAVID</software> and <software>CLUSTALW</software> (Figure 10b(1),c(1),d(1)). Again, we observed marked differences in performance between different tools for three or more species alignments. Overall, <software>MUSCLE</software> had the highest detection accuracy among all tools across all divergence scale coefficients; <software>MAVID</software> had a slightly worse performance than all other tools; and <software>CLUSTALW</software>, <software>DIALIGN</software> and <software>MLAGAN</software> showed similar performance, although their relative order in performance varied with the number of species or a change of the divergence scale coefficient. As expected, the TFBS detection accuracy decreased for all tools as the divergence scale coefficient increased. <software>PSPE</software> also allowed us to consider only the set of sites that had not turned over, and the relative performance of tools was unchanged (Figure 10a(2),b(2),c(2),d(2)). With increasing distance, a large fraction of sites has turned over, but many of those trace back to the same ancestral nucleotides in several descendants, due to turnover before a branch in the tree or convergent evolution. These sites should thus be aligned and are counted positive in at least some of the pairwise comparisons that our metric is based on, even if they are not in the location of the original TFBS (see Additional data file 2 for more evaluations on turnover sites).<br>
The ability of a tool to detect the presence of a common TFBS varied among different TFBSs, depending on TFBS base composition, length, and restricted translocation distance, as well as the divergence scale coefficient of the phylogenetic tree. For example, Figure 11 shows that detection accuracies differed significantly among TFBSs in the alignments of the five species. In addition, the same figure shows that all tools had higher detection accuracies for TFBSs with low RTRs, such as YY1E2F and Pax6, than those with high RTRs, such as IRF2 and ROAZ. While <software>MUSCLE</software> showed a better performance than all other tools, <software>CLUSTALW</software> as the oldest tool performed slightly better than <software>DIALIGN</software>, <software>MAVID</software>, and <software>MLAGAN</software> in at least some cases (YY1E2F and ROAZ). Additionally, for YY1E2F, Pax6 and TP53, <software>MUSCLE</software> showed higher TFBS detection accuracies than the baseline of <SimuALN info="SimuALN stands for the simulated alignment">SimuALN</SimuALN>, suggesting its capability of correctly aligning at least some TFBSs subject to turnover, that is, homologous only at the functional level. At large divergence scale coefficients, however, no tool seemed to perform well in detecting ROAZ.<br>
When looking at the performance of each tool individually (Figure 12), we found that the TFBS detection accuracies of all tools decreased when adding one or more distant species to the human/baboon alignment. For alignments from three to five species, the TFBS detection accuracies of <software>DIALIGN</software> and <software>MUSCLE</software> showed little change, those of <software>CLUSTALW</software> and <software>MLAGAN</software> had a noticeable change and that of <software>MAVID</software> markedly decreased, especially at large divergence scale coefficients. We also compared tool performance again with respect to overall alignment sensitivity and TFBS sensitivity. We found that in terms of alignment sensitivity, <software>MUSCLE</software> and <software>CLUSTALW</software> had slightly better overall performance than the other three (data not shown). The ranks according to TFBS sensitivity were also in the same order as those according to detection accuracies, and this was also true if we considered non-turnover sites only (Figure 13).<br>
<br>
<br>
Discussion<br>
In the process of evolution, selection may act directly on regulatory functions but only indirectly on gene sequences, which is supported by the experimental observations that some orthologous genes with highly conserved expression patterns have substantial divergence in their promoter sequence [7-9]. That means that functional conservation does not necessitate conservation on the sequence level. Neutral sites in promoter sequences may be free to change, and newly evolved functional sites can readily replace old ones. It is important, therefore, to understand the evolutionary mechanisms of regulatory regions in order to improve computational methods that are developed to analyze them. However, it is difficult to investigate systematically non-protein-coding evolution on real sequence data because the history of evolutionary events shaping them is largely unknown, and the map of functional sites in regulatory sequences is often incomplete and inaccurate. In many cases, there is no simple way to distinguish a site newly evolved in a replacement turnover event from one created by simple translocation of an old site. Computational simulation seems to be an effective alternative to study TFBS evolution in this case. Simulators allow us to investigate evolutionary events such as replacement turnovers of TFBS, which may significantly limit the effectiveness of phylogenetic footprinting for regulatory region identification, in an explicit way. Here, we describe a new sequence simulator to investigate the effect of different functional constraints on turnover rates, and to create a framework to evaluate multiple sequence alignment algorithms regarding their ability to detect functional elements in the presence of turnover events.<br>
Simulation of TFBS turnover<br>
Our simulator <software>PSPE</software> is designed specifically for studying the evolution of functional sites in regulatory sequences. <software>PSPE</software> is not only able to use one of many common models of nucleotide substitution, but it can also apply different InDel models important for regulatory sequence simulation. In contrast to other simulators, <software>PSPE</software> imposes a variety of functional constraints instead of sequence constraints. Such functional constraints include GC content, presence of functional sites, strength of the binding sites, location and copy number restrictions on functional sites, and space constraints between different functional sites. All these features enable <software>PSPE</software> to simulate evolution of promoter sequences more realistically than other simulation programs.<br>
Consistent with previous simulation studies [5,14], our results show that TFBS turnover can occur rapidly in promoter evolution. For example, replacement turnover events can occur at a Poisson rate as high as 0.083 for the highly constrained E2F sites even if we only allow for a small translocation distance of 50 nucleotides, and is even higher for the less constrained sites of Myc (0.22) and NF?B (0.103). Furthermore, these parameters may be relatively conservative considering that we used stringent matrix score cutoffs to avoid false hits, highly restricted locations for functional sites, a relatively low rate for transversions, and the requirement of the presence of exactly one functional site throughout. However, a high turnover rate of TFBSs can frequently be detrimental to an organism, and highly increased turnover rates may not be observed in practice, even for degenerate sites. This is supported by an additional simulation study we carried out using a lower cutoff threshold of 0.85 for functional sites, in which promoters with Myc sites had a lower RTR despite the higher chance of creating a new site at the lower cutoff. This was mainly due to our restriction of allowing only one site to be present in the promoters (see Additional data file 1 for details). Therefore, TFBS replacement turnovers in real sequences may happen more frequently than we estimated, but there is an upper limit of turnover rate for each individual TFBS imposed by the resulting changes in fitness.<br>
Altogether, our study suggests that the TFBS RTR of a functional site between different species does not depend only on the base composition of the site and the divergence distances between species, but also on location constraints, neighboring functional sites, the InDel rate, and the GC content. While not discussed in detail, a simulation using lower GC contents showed a consistently higher or lower RTR depending on the TFBS, suggesting that the high GC content in promoter regions near the TSS is affecting the turnover rates of important functional sites (Additional data file 1). Consequently, the RTR varies not only among different functional sites and different species, but also among different instances of the same functional site upstream of different genes.<br>
While we attempted to choose realistic model parameters and biologically meaningful functional constraints in our simulations, our estimates are certainly biased by the assumptions behind the chosen constraints, and may be substantially different from the real ones. Furthermore, the TFBS and evolution models themselves represent simplified versions of the underlying biological processes, and other factors, such as the number of replicates used in the simulation, can add some additional variation as well. We realize that the weight matrices used here as models of functional sites may not be as adequate for modeling positional dependencies as other more advanced motif models [52,53]; however, PWMs are a valid model for many biological motifs, are available in open-access databases, and are computationally more efficient than other advanced models. Computational efficiency is an important factor in simulation studies that are as large as this one.<br>
Simple evolutionary changes within regulatory regions, such as turnover events affecting individual sites only, can be modeled effectively by Poisson events. We could show good agreement of this for a variety of binding sites and conditions, such as different translocation distances. In theory, one could derive closed-form solutions for the probability of these events, based on the sequence composition of the region and the composition and degeneracy of a binding site. However, with an increasing number of restrictions and dependencies of sites in complex regulatory modules, this becomes increasingly cumbersome and not straightforward. Figure 6c showed that these simple models begin to deviate as soon as we address the conservation on the module level instead of individual sites only.<br>
One can easily think of a large number of additional parameters and configurations of functional sites that we did not explore. A tool such as <software>PSPE</software> will allow researchers to explore empirically a wider range of restrictions and complex configurations of regulatory regions in an efficient manner. Enhancers come in many different flavors, from highly restricted 'enhanceosomes' corresponding to ultra-conserved elements, to highly flexible 'billboard' enhancers allowing for many drastic sequence changes without apparent functional consequence [54]. <software>PSPE</software> is available to the public and we anticipate that it will be a beneficial tool for evolutionary biologists to explore the specific characteristics and evolutionary space of particular regulatory systems. Future extensions may include an adaptation for RNA regulatory regions, including specific modeling of compensatory mutations in RNA secondary structure, incorporating transposable elements, and neighbor-dependent substitution models.<br>
<br>
Assessment of MSA tools<br>
During evolution, natural selection forces impose different functional constraints on protein coding and regulatory regions. The phenomenon of frequent TFBS turnovers in regulatory regions may partially explain why comparative genomics analysis, the most powerful approach so far, has met with only limited success in identifying functional sites despite the increasing availability of whole genome sequences. TFBS turnovers may also be responsible for the weak relationship between sequence conservation and functional conservation in promoter sequences, which makes the straightforward tracing of nucleotide evolution between divergent orthologous sequences meaningless with respect to their function. Our strategy of defining conservation on the level of functional constraints such as matrix score cutoffs is similar to a recent model, which defines conservation on the level of conserved binding energy [55]. In this sense, functional homology maps of regulatory regions, where mapped elements correspond to functionally equivalent sites, can be more important than strict sequence homology.<br>
While many alignment tools have been developed so far, it is difficult to systematically evaluate and compare these tools, especially regarding their performance in aligning non-coding sequences, for which we have a limited understanding of evolutionary constraints. Studies that rigorously assess alignment tools (for example, [28]) can serve as useful reference for making more informed decisions about which tool to use for which task, and can also provide important insights or suggestions for improvement of existing algorithms. Most published evaluations of alignment algorithms were based on alignment sensitivity, specificity, and accuracy, and did not address replacement turnover of functional sites in evolution. The evaluation reported here is different: instead of trying to systematically assess all different performance aspects, we focus on one particular scenario, the capability of accurately aligning conserved TFBS in promoter sequences. Specifically, our evaluation was based on two aspects: the capability of aligning functionally homologous TFBS in promoter sequences in which TFBS replacement turnovers are allowed to occur; and the capability of increasing TFBS detection power with an increase in the number of homologous aligned species.<br>
The five tools selected for our evaluation are representatives of many existing tools of different underlying algorithms. These differences were clearly reflected in the success of aligning TFBSs, which ranked <software>MUSCLE</software> at the top, <software>AVID</software>/<software>MAVID</software> at the bottom, and others in between. We purposefully chose transcription factors with long binding sites, and required strong conservation of orthologous sites (that is, a high matrix score threshold for each site). Furthermore, while our choice of constraints allowed for turnover events, it did not allow for a shuffling of sites, which none of the programs can take into account. Yet, our results suggest that the ability of existing tools to detect functionally homologous elements decreases with increasing replacement turnover rates of functional sites or, related, the sequence divergence distance. An increased divergence of the non-functional parts of the sequence does thus not necessarily help to locate individual functional binding sites, even if the sites are highly conserved and 15-20 bp long.<br>
It is often reported that an increase in the number of species may significantly increase the power for functional site identification in comparative genomics analyses [56]. On the contrary, our evaluation results show that we should be extremely cautious at this point to assume that this is a general property of many functional DNA regions and/or tools to analyze them. With the exception of <software>DIALIGN</software>, the TFBS detection accuracy of all tools was either decreased or relatively unchanged in most cases. This is in fact not surprising when ones take a closer look at the approaches used for multiple sequence alignment. <software>CLUSTALW</software>, <software>MAVID</software>, and <software>MLAGAN</software> all use the same progressive approach for aligning multiple sequences, in which intermediate alignments from the early stages are not allowed to change in later stages. That means that the mistakes that happen in an early stage of alignment will be propagated and cannot be corrected at a later stage. Since a tool based on the progressive approach can only accumulate more mistakes when aligning more sequences, it is conceivable that its performance decreases as the number of species increases. <software>MUSCLE</software> employs an improved progressive approach that allows changes in the alignment of sub-groups in a recursive refinement process, which explains why <software>MUSCLE</software> did not show a significant decrease in performance as the number of species increased. It is conceivable, however, that the particular choice of species, and the order in which they are presented to a phylogenetic aligner, may significantly change the accuracy of these approaches. <software>DIALIGN</software> is the only tool surveyed here that does not use the progressive approach. Instead, it assembles the whole alignment by greedily finding all consistent segments of significant similarity from all sequences [57], which allows <software>DIALIGN</software> to be able to take advantage of the information from additional species. While these features of <software>DIALIGN</software> are interesting, there is still much room for improvement as its overall performance is no better than <software>MUSCLE</software>.<br>
We want to stress that the tools in this study were not specifically developed for the alignment of non-coding regions. In fact, some design principles may be counterproductive for this task: whole genome alignments are built to provide fast comparative maps and are certainly able to detect coding conservation. The progressive aligners in our evaluation are meant to provide the phylogenetic history, that is, to compute an accurate alignment of bases that are derived from the same nucleotide in the ancestral genome. Yet, there is no doubt that many researchers currently use these tools in studies concerning gene regulatory sequences, and we hope that this evaluation provides clues about what to expect if they are used in this way. We aimed to include a representative subset of tools fast enough to perform extensive comparisons. We do not expect this to have introduced a systematic bias, but of course some recently developed aligners (for example, <software>TBA</software> [58], <software>Prank</software> [59], or <software>Probcons</software> [60]) may perform differently to our selected set.<br>
The objective and systematic evaluation of alignment tools is a challenging task, in particular for an assessment on non-coding sequences whose actual functional and evolutionary mechanisms remain largely unknown. Since we simulated data under a set of specific conditions that are unlikely to represent all actual scenarios, one should carefully interpret our comparison results. For example, our study did not consider the ability of a tool to deal with very large insertions and deletions because of few large insertions/deletions in our simulated data. Furthermore, we were very conservative in our constraints, and, for example, allowed for turnover, but not for a shuffling of sites. Our results are therefore a rather optimistic estimate, and performance on real promoters with shorter sites that do not preserve their order can be expected to be significantly worse. We are also aware that the criteria for tool performance can be different in a different study depending on its objectives. Therefore, our results may not be applicable for some studies, such as the estimation of divergence distances between species. For such cases, the recent evaluation by Pollard et al. [29] may be a better reference.<br>
<br>
<br>
Conclusion<br>
TFBS replacement turnover is an important phenomenon in the process of promoter evolution, and providing a framework to address it systematically is critical for our understanding of the mechanisms driving promoter evolution. We introduced the new simulation system <software>PSPE</software>, designed specifically for regulatory sequences, and allowing for functional site turnover events. <software>PSPE</software> is freely available at the authors' websites [61,62]. Applying <software>PSPE</software> in a large-scale simulation, we found that replacement turnovers could happen rapidly in promoter evolution. We also investigated different factors besides the divergence distance that significantly affect turnover rates, and describe the relationships between the RTR and different factors in simple mathematical models. Our study adds to the increasing evidence that it is important and advantageous to trace homology on the functional rather than on the sequence base-pair level in cross-species comparisons of regulatory sequences.<br>
<software>PSPE</software> also provides a flexible system to generate appropriate standard test sets for alignment or motif finding algorithms, and we presented first results of this application. To our knowledge, our evaluation of MSA tools is the first one to assess their ability to detect TFBSs that are homologous on a functional level. Our evaluation of five widely used MSA tools suggests that the turnover of functional sites poses a challenge for alignment tools, even for the simplified case where the functional sites remain co-linear in orthologous sequences. While all MSA tools under consideration, especially <software>MUSCLE</software>, performed well in aligning functional sites at short or moderate divergence distances, they appeared to lack sufficient capability to align functional sites that have high RTRs in divergent sequences. In addition, our study suggests that the widely used progressive approach for MSA is counterproductive for the multiple alignments of homologous non-coding sequences, and that <software>MUSCLE</software>'s improved progressive approach and <software>DIALIGN</software>'s segment assembling approach are better suited for non-coding MSA. Some recent approaches are promising to successfully deal with the specific challenges of non-coding alignments, for example, by using available models of TFBS to 'anchor' alignments [63]. However, this still leaves us with a number of open issues on the way towards computational tools that will help us to elucidate the structure and evolution of regulatory regions.<br>
<br>
Materials and methods<br>
Background model of ancestral sequences<br>
To generate biologically relevant ancestral sequences, we used a 3rd order Markov model to generate background sequences of ancestral promoters. We trained the background Markov model on a large real dataset of regulatory sequences extracted from the NCBI human <database>RefSeq</database> database (build 35). The dataset consists of 25,088 human promoter sequences each spanning a region of 500 bp immediately upstream of the transcription start sites. The base frequencies of four nucleotides were also estimated on this dataset.<br>
<br>
Selection of E2F regulated ancestral genes<br>
We obtained 127 experimentally confirmed E2F regulated genes from a previous publication [42]. We removed the genes for which we were not able to extract their promoter sequences from NCBI, and extracted 500 bp long promoter sequences upstream of their annotated transcription start site. We then identified potential E2F sites in each promoter sequence using the PWM model. We removed those genes that had either zero or more than one E2F binding site based on the cutoff score of 0.92 given in Figure 3. The remaining 11 genes are given in Additional data file 1 and were used as ancestral sequences for our simulation study.<br>
<br>
Motif model of TFBSs<br>
We used the PWM, a generic and widely used model for DNA motifs, to represent functional TFBSs. The PWM is generally given by a matrix with frequencies (or weights) of the four nucleotides at each position. While there are several different methods to calculate a motif score, we used a scoring function similar to the one proposed by [64] and defined by:<br>
Score=?i=1w?i?fib?i=1w?i?max?b?(A,C,G,T)fibwhere??i=1+ln?4??bfibln?(fib),i=1...w.<br>
The function gives a normalized score from 0 to 1 for any TFBS, with 0 for the most unlikely and 1 for the most likely site. A functional binding site defined in this study is a site having a score larger than a certain cutoff threshold.<br>
Position weight matrices of E2F, Myc, and NF?B were taken from the <database>JASPAR</database> database [39,65]. The functional sites in simulated ancestral sequences were generated from these PWMs. To maintain a low false positive rate of binding sites, we chose a relative strict cutoff score for each TFBS. At a cutoff score of 0.92, we estimated the fraction of false positive predictions to be less than 5% of the total number of planted sites on coding regions of human genes in the <database>RefSeq</database> database.<br>
<br>
DNA substitution models<br>
<software>PSPE</software> is able to use many different commonly used models for nucleotide substitution, including Jukes-Cantor (JC) [66], Felsenstein 1981 (F81) [67], Kimura 2-parameter (K80) [68], Hasegawa-Kishino-Yano (HKY) [40], Tamura-Nei (TrN) [69], and the general time reversible (GTR) model [70-72]. The GTR model has eight free parameters with the following instantaneous substitution rate matrix:<br>
Q=[qaa?ac?c?ag?g?at?t?ca?aqcc?cg?g?ct?t?gg?a?gc?cqgg?gt?t?tt?a?tc?c?tg?tqtt]<br>
where ?ij is the instantaneous substitution rate of nucleotide i by j, ?i is the frequency of nucleotide i, and qii=?j?i?ij?j where i = a, c, t, g; j = a, c, t, g. The other substitution models above can be expressed as special cases of the GTR model. From the Q matrix, we can obtain the matrix of nucleotide transition probabilities in continuous time by:<br>
P(t) = ekQrt<br>
where k is a correction factor, which is used to scale the substitution matrix such that branch lengths represent the expected number of substitutions per site, and r is the relative substitution rate to model heterogeneous substitution rates among different sites. Based on the ?+I model [73,74], the relative rates at each position follow the same independent and identical distribution as defined by:<br>
f(r|?,?)={0if?r&lt;0?if?r=0(1??)(??r)?e??r/r?(?)if?r&gt;0<br>
where ? is the proportion of invariant rates and ? is the shape parameter of the gamma distribution.<br>
<br>
InDel models<br>
<software>PSPE</software> is based on <software>Dawg</software> [75], an earlier sequence evolution simulation system, and in particular adopted its range of InDel formation model. The model is based on a Poisson process that assumes InDel formation to happen at a fixed, instantaneous rate at any site. The model treats insertions and deletions as two separate processes. Under the model, the time intervals between two insertions and those between two deletions follow exponential distributions with means [?Ins (L + 1)]-1 and [?Del (L + u - 1)]-1, respectively, where L is the sequence length, u is the mean length of deletion segments, and ?Ins and ?Del are Poisson rates of insertion and deletion, respectively.<br>
<software>PSPE</software> models InDel length by one of three commonly used distributions: geometric, negative binomial, and Zipf's law distributions. We used the simple geometric distribution for InDel length in this study.<br>
<br>
Simulation of sequence evolution<br>
To address TFBS turnover at different distances, we simulated sequence evolution at each of 15 different divergence distances: 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.5, 3.0, 4.0, and 5.0, measured in the number of substitutions per site. These distances should cover the divergence between most currently sequenced genomes used in comparative genomics studies. To study the effect of different InDel rates on TFBS conservation between human and mouse, we performed simulations at ten different InDel rates measured by the number of InDels per substitution: 0, 0.01, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2, with, for example, 0 meaning no InDel, and 0.2 meaning one InDel every five substitutions. For studying the effects of restricted translocation distances on the RTRs, we compared RTRs of each TFBS at 12 different maximal translocation distances: 0, 5, 10, 20, 30, 40, 50, 75, 100, 150, 200, and 300 bases.<br>
<br>
Model fitting method<br>
To estimate parameters of our RTR models, we did a non-linear least-squares regression analysis on the observed turnover data from simulation. We used the Gauss-Newton algorithm for the non-linear least-squares fitting, which minimizes the sum-of-squares error. We performed this analysis in <software>R</software>.<br>
<br>
Alignment tools<br>
We selected five alignment tools, <software>CLUSTALW</software>, <software>DIALIGN</software>, <software>AVID</software>/<software>MAVID</software>, <software>LAGAN</software>/<software>MLAGAN</software>, and <software>MUSCLE</software>, to assess their capability of detecting functional sites. The criteria for our selection were: either widely used or shown good performance in other studies for aligning DNA sequences; capable of aligning multiple sequences in a reasonable amount of time; free availability and easy installation in the Linux operating system; and strict co-linearity for global alignment. Many excellent alignment tools were not evaluated because: they did not meet one of the above criteria; their algorithms were similar to one of five tools we selected; and/or they did not show a significantly different performance in other evaluations. For example, <software>ACANA</software> [21], <software>BLASTZ</software> [76], <software>MUMmer</software> [77], and <software>SSEARCH</software> [78] were not selected because of the first criterion, and <software>T-COFFEE</software> [22], <software>POA</software> [79] and <software>MAFFT</software> [80] were not evaluated due to the second criterion. Our study is therefore not considered to be a systematic evaluation of all available good alignment tools and rather as a representative but somewhat subjective cross-section. Each of the five tools is briefly described below.<br>
<software>CLUSTALW</software> (v1.83) is one of the best-known MSA tools and is based on a progressive method, which first aligns the most similar sequences and then successively adds more distant sequences or groups to the alignment until all sequences are aligned together. <software>CLUSTALW</software> employs the Needleman-Wunsch pair-wise alignment algorithm for calculating similarities between sequences and constructing a phylogenetic guide tree. We ran <software>CLUSTALW</software> with its default settings.<br>
<software>DIALIGN</software> (v2.2.1) is an anchor-based MSA tool for both DNA and protein sequences. Different from other alignment tools, <software>DIALIGN</software> assembles alignments by finding consistent segments exhibiting statistically significant similarity, and does not align regions showing no significant similarity. Therefore, strictly speaking, <software>DIALIGN</software> is a local alignment tool that produces a full global alignment only for sequences with high similarity. Recent studies [21,28,79] suggested that <software>DIALIGN</software> performed well in aligning sequences of low similarity with long insertions and deletions. <software>DIALIGN</software> was run with default parameters.<br>
<software>AVID</software> (v2.1) is a pair-wise global alignment tool that is capable of aligning very large genomics sequences. Its employs an anchor-based approach and uses a suffix tree algorithm for identifying potential anchoring regions between sequences. <software>MAVID</software> (v2.0.4) is a progressive MSA tool and is the direct extension of <software>AVID</software>. To speed up the alignment process, <software>MAVID</software> does not directly align two intermediate alignments or groups; instead, it first infers the common ancestral sequence of each alignment by maximum likelihood, and then uses <software>AVID</software> to align two ancestral sequences. We used <software>AVID</software> for two-species alignments, and <software>MAVID</software> for three or more species. <software>CLUSTALW</software> at default settings was used as the tree building tool for <software>MAVID</software>.<br>
<software>LAGAN</software>/<software>MLAGAN</software> (v1.21) is a suite of programs for aligning DNA sequences. As an anchor-based pair-wise alignment tool, <software>LAGAN</software> first identifies anchoring regions by chaining similar neighboring words found in a local alignment process, and subsequently aligns other regions by the Needleman-Wunsch algorithm to form a global alignment. <software>MLAGAN</software> is a progressive multiple sequence alignment tool based on <software>LAGAN</software> pair-wise alignments. Similar to <software>CLUSTALW</software> in scoring multiple sequence alignments, it uses the sum-of-pairs approach for scoring substitutions and a consensus-based method for scoring gaps. Since <software>MLAGAN</software> does not build a phylogenetic tree, which is a required input, we provided it with the phylogenetic tree from our simulation. In this study, <software>LAGAN</software> was used for two-species alignments and <software>MLAGAN</software> for three or more species. Both tools were run with default settings.<br>
<software>MUSCLE</software> (v3.6) is a relatively new MSA tool for both DNA and protein sequences based on an improved progressive approach. Like <software>CLUSTALW</software> and <software>T-COFFEE</software>, <software>MUSCLE</software> is based on a progressive approach, and uses the sum-of-pairs scoring scheme for multiple alignments, but it differs from other progressive tools by allowing changes of both the phylogenetic tree and the alignment in intermediate steps in an iterative refining process. <software>MUSCLE</software> was shown to perform better than <software>T-COFFEE</software> and <software>POA</software> in aligning benchmark protein sequences [20,81]. Because <software>MUSCLE</software> is quite slow when running on default settings, we used its diags option for anchoring alignment and maxiters option to limit the number of refinement iterations to two.<br>
<br>
Simulation of alignment benchmark data<br>
The benchmark sequence datasets were simulated by the <software>PSPE</software> system. <software>PSPE</software> sequence simulation can be generally divided into two separate steps. In the first step, <software>PSPE</software> generates ancestral promoter sequences with different functional TFBSs (see Table 6 for the sites we used in this study). With the exception of YY1E2F, a composite of YY1 and E2F and chosen on purpose for this study, the TFBS sites used here were arbitrarily selected among those satisfying three criteria: binding site of a human transcription factor; PWM available in the <database>JASPAR</database> database; and length between 12 and 25 bp. A motif instance, which is generated randomly from a PWM, is defined as a functional site if its score is larger than a certain cutoff value. To avoid degenerate motifs, we used a relatively stringent cutoff of 0.90 for all TFBSs. <software>PSPE</software> first generates functional sites and a map of their locations, and then fills the remaining region in promoters with background sequences. To generate biologically relevant background sequences, we estimated parameter values of a 3rd order Markov chain from a large real sequence data set and used them to simulate the ancestral background sequences. The actual sequence data consisted of human promoter sequences of 24,649 transcripts extracted from the NCBI human <database>RefSeq</database> database (build 35). Each sequence in the training data comprises a 5,000 bp region upstream of the putative transcription start site.<br>
In the second step, <software>PSPE</software> simulates descendent sequences from the simulated ancestral promoter sequences according to specified evolutionary models and functional constraints (Table 5). For the evaluation on the mammalian tree of five species, we scaled the tree, relative to evolutionary distance, at the following eight levels: 0.25, 0.5, 1, 1.5, 2, 3, 4, and 5, which we refer to as divergence scale coefficient. At each scale level, <software>PSPE</software> generated 1,000 sets, each consisting of five descendent mammalian sequences from their common ancestral sequence of length 3,000 bp.<br>
<br>
Performance measures<br>
We use the expressions 'a tool alignment' to refer to an alignment produced by an alignment tool, 'a simulated alignment' to refer to a correct alignment of homologous base pairs from the simulation, and 'a simulated TFBS map' to refer to a correct alignment of TFBSs homologous on the functional level. Both 'a simulated alignment' and 'a simulated TFBS map' were generated by the <software>PSPE</software> simulator. The ability of an alignment tool to detect functional sites was assessed by TFBS detection accuracy. Tool performance was also assessed by four additional measures: overall alignment sensitivity, overall alignment specificity, TFBS sensitivity and TFBS specificity, which are similar to measures in [28]. Definitions of these measures are given below.<br>
TFBS detection accuracy (DA) is defined as the proportion of functional sites correctly aligned with respect to a simulated TFBS map, averaged over all different pairs in a multiple sequence alignment, and can be calculated by:<br>
DA=2n(n?1)L?i=1n(n?1)/2?j=1Laij<br>
where n is the number of sequences in the alignment, n(n-1)/2 is the number of different sequence pairs, and L is the total length of functional sites (for a DA of an individual functional site, L is the length of the site). aij has a value of 1 if the bases at the jth position of functionally homologous binding sites in a sequence pair i are aligned to each other and 0 otherwise. Since all our simulated sequences contain the same set of TFBSs, L is the same for all alignments.<br>
The overall alignment sensitivity is the fraction of correctly aligned bases not considering gaps, averaged over all different pairs in a tool alignment:<br>
overall_sensitivity=2n(n?1)?i=1n(n?1)/21ki?j=1kicij<br>
where ki is the total number of positions for which bases are aligned to bases in the ith pair-wise alignment from a simulated alignment. cij has a value of 1 if the jth position was aligned correctly in any given pair of sequences i in the tool alignment, and 0 otherwise.<br>
Overall alignment specificity is the fraction of correctly aligned bases among those that are aligned to gaps in a simulated alignment, averaged over all different pairs in a tool alignment:<br>
overall_specificity=2n(n?1)?i=1n(n?1)/21gi?j=1gicij<br>
where gi is the total number of positions, where bases in one sequence aligned to gaps in the other sequence in the ith pair-wise alignment of a simulated alignment; cij has a value of 1 if the jth position aligned correctly, and 0 otherwise.<br>
TFBS sensitivity is the fraction of correctly aligned bases, among those in functional sites of ancestral sequences and not aligned to a gap in a simulated alignment, averaged over all different pairs in a tool alignment:<br>
tfbs_sensitivity=2n(n?1)?i=1n(n?1)/21li?j=1licij<br>
where li is the total number of positions in functional sites of ancestral sequences, where bases in one sequence aligned to bases from the other sequence in the ith pair-wise alignment of a simulated alignment; cij has a value of 1 if the jth position aligned correctly, and 0 otherwise. In case of no replacement turnovers of TFBSs, TFBS sensitivity is equal to TFBS detection accuracy.<br>
TFBS specificity is the fraction of correctly aligned bases, among those in functional sites of ancestral sequences and aligned to gaps in a simulated alignment, averaged over all different pairs in a tool alignment:<br>
tfbs_specificity=2n(n?1)?i=1n(n?1)/21L?li?j=1L?licij<br>
where L is total length of all functional sites in the ancestral sequence.<br>
In this paper, we mostly use detection accuracy and TFBS sensitivity. The former refers to the fraction of functional sites in the 'descendants' aligned to each other, the latter to the fraction of sites corresponding to the location of the TFBS in the 'ancestral' sequence that are correctly aligned to each other.<br>
<br>
<br>
Abbreviations<br>
GTR, general time reversible; HKY, Hasegawa-Kishino-Yano; InDel, insertion/deletion; MSA, multiple sequence alignment; <software>PSPE</software>, <software>Phylogenetic Simulation of Promoter Evolution</software>; PWM, position weight matrix; RTR, replacement turnover rate; TFBS, transcription factor binding site; TSS, transcription start site.<br>
<br>
Authors' contributions<br>
WH, JN and UO contributed to the conception and design of this study. WH developed <software>PSPE</software>, performed analyses, and drafted the initial manuscript. WH and UO provided the interpretation of results. All authors contributed to writing and critically revising the manuscript. All authors read and approved the final manuscript.<br>
<br>
Additional data files<br>
The following additional data are available with the online version of this paper. Additional data file 1 provides additional results of turnover simulations varying the binding site strength and GC content of the background sequences, and information on the E2F promoter data set. Additional data file 2 provides additional evaluations of alignment algorithms on sequence sets simulated with a phylogenetic tree with a star topology.<br>
<br>
Supplementary Material<br>
<br>
<br>
<br>
<p><hr><p>

<b>PMC193626</b><br>
Understanding the language of gene regulation<br>
A report on the Cold Spring Harbor Laboratory meeting 'Systems Biology: genomic approaches to transcriptional regulation', Cold Spring Harbor, USA, 6-9 March 2003.<br>
<br>
<br>
On the snow-covered coast of Long Island, the community of researchers dedicated to understanding how DNA sequences selectively activate gene transcription gathered to assess progress in the field, to celebrate recent successes and to plot future directions. The theoretical foundations of the field were established in the 1980s. In laboratory studies, the concept of regulatory modules was established, introducing the idea that transcription-factor binding sites are grouped in functional clusters in regulatory sequences. In bioinformatics, the first predictive models were introduced for the identification of potential binding sites for well-characterized transcription factors and 'phylogenetic footprinting' was formally introduced for the identification of regulatory sequences conserved between orthologous genes. The recent influx of researchers into the field is a testament to the opportunities presented by emerging genomic resources such as large-scale expression data, transcription-factor binding data and full genome sequences of multiple eukaryotic genomes. For researchers pursuing studies in diverse model organisms (such as yeast, worm, fly, vertebrates, and Arabidopsis), the clear message of the conference was that the early theoretical ideas are broadly applicable. The presentations centered on three main themes: quantitative descriptions of protein-DNA interactions, prediction and characterization of clusters of transcription-factor binding sites, and the analysis of co-regulated systems of genes.<br>
<br>
Describing protein-DNA interactions<br>
Efforts to study gene regulation are founded on the determination of how transcription factors and DNA interact. Modeling of the DNA-binding preferences of transcription factors has so far mainly used single-order positional weight matrices - that is, matrices of the bases preferred at each position of a binding site assuming that the nucleotide observed at one position is independent of the nucleotide found at any other position. Recent published reports in which large collections of transcription-factor binding sites were generated and analyzed indicate that this underlying assumption is false. In a retrospective analysis of the collections, Gary Stormo (Washington University, St. Louis, USA) explained that the underlying assumption is adequate in most cases, because inclusion of positional correlations gives only a marginal improvement in the specificity of binding-site predictions. Stormo gave an inspiring call for researchers to use the techniques for generating large sets of transcription-factor binding sites to define quantitatively the target-nucleotide preferences of amino acids that directly interact with DNA. Using in vitro binding data for zinc-finger transcription factors, Stormo generated a quantitative matrix profile for the prediction of amino-acid:base interactions. The current shift in focus from the analysis of target sequences to the protein-DNA interface was reflected in posters from Barry Honig's lab (Columbia University, New York, USA) presenting methods for predicting the binding properties of uncharacterized transcription factors using the refined structures of DNA-bound factors from the same structural class.<br>
A particular constraint on the analysis of regulatory sequences is the sparse data available on the binding preferences of transcription factors. A practical approach towards the analysis of protein-DNA interaction was presented by Martha Bulyk (Harvard Medical School, Boston, USA). She used 'protein binding microarrays', in which phage-displayed transcription factors are bound directly to microarrays of double-stranded DNA. Quantitative data on the level of binding of each protein to each spotted sequence were used to determine the binding-site specificity for zinc-finger transcription factors directly from differences in fluorescence intensity. The resulting matrix describing the observed binding preferences of each protein provides better specifrcity in predicting suitable transcription-factor binding sites than previous models. In one of the highlights of the conference, Rick Young (Whitehead Institute, Massachusetts Institute of Technology, Boston, USA) introduced results from a high-throughput screening procedure to identify binding sites for yeast transcription factors. The experiments used crosslinked chromatin immunoprecipitation of transcription factors followed by microarray analysis ('ChIP on chip'), and the results obtained define sets of genes containing promoter sequences that are bound by the transcription factors tested. The new approach to the genome-scale characterization of transcription-factor binding properties has influenced research in the field enormously.<br>
<br>
Prediction of cis-regulatory elements<br>
The study of composite response elements - or regulatory modules - dominated the presentations on regulatory regions in metazoan genomes. Because the ability of current approaches to predict isolated transcription-factor binding sites is poor (as was widely noted during the conference), various groups presented novel methods - and experimental assessments of published methods - for the detection of clusters of binding sites. Most algorithms involve counting the occurrences of predicted binding sites for user-defined sets of transcription factors; the algorithms differed in the procedures for counting and how the significance of predictions was assessed. Susan Celniker (Lawrence Berkeley National Laboratory, Berkeley, USA) and Marc Halfon (Howard Hughes Medical Institute and Brigham and Women's Hospital, Boston, USA) identified functional regulatory regions in Drosophila melanogaster by counting instances of binding sites for transcription factors involved in regulation of the even-skipped(eve) gene, which itself encodes a transcription factor important in developmental patterning. Both used a phylogenetic-footprinting step, incorporating comparison with the nearly complete genome of Drosophila pseudoobscura, to prioritize their predictions for experimental testing. Some of the regions identified by these methods showed regulatory activity, but further analysis of wider samples of predictions indicated that the overall performance of the methods was low. On this point, Halfon remarked that these clustering methods may be better suited to identifying true regulatory regions in the very early stages of embryonic development than clusters that are functional in later stages of development.<br>
Many speakers touched on the idea of using phylogenetic footprinting to increase the specificity of algorithms that predict regulatory sequences. The broad applicability of phylogenetic footprinting was supported by promising results in species ranging from bacteria to multicellular eukaryotes. Dario Boffelli (Lawrence Berkeley National Laboratory, Berkeley, USA) introduced the concept of 'phylogenetic shadowing', in which multiple sequence comparisons are made between orthologous genes across short evolutionary distances, taking relationships into account. Applying this method across a set of closely related primates, he demonstrated that it can reveal functional regulatory sequences. In contrast to these closely related species, Elliott Margulies (National Human Genome Research Institute, National Institutes of Health, Bethesda, USA) analyzed a set of orthologous sequences from a spectrum of vertebrates, from human to zebrafish. He introduced a scoring function for the analysis of multi-species conserved sequences (MCS). In calculating the MCS score, the contribution of the sequence from each non-human species is weighted according to the percentage of identical nucleotides observed in alignments of syntenic, neutrally-evolving sequences from the species and humans. It appeared that the scores for coding MCSs were significantly higher than the scores for non-coding MCSs. Using a threshold heuristically determined to separate the two classes, he predicted potential regulatory regions in a portion of human chromosome 7.<br>
Phylogenetic footprinting alone is not sufficient to define regulatory regions, however. Eric Siggia (Rockefeller University, New York, USA) demonstrated that when phylogenetic footprinting is used to locate known regulatory regions in D. pseudoobscura and Drosophila virilis, only 50% of the known regulatory regions fall within sequences that are conserved between these species. Furthermore, several groups doing human-rodent comparisons reported a failure to detect the anticipated functions in well-conserved regions. The combination of multi-species phylogenetic footprinting with robust models of composite response elements holds the most promise for unraveling the complex regulatory mechanisms governing transcription.<br>
<br>
Modeling regulatory systems<br>
Two distinct approaches were introduced for the study of gene interactions in transcriptional regulation. The first, the construction and study of simple artificial regulatory systems in Escherichia coli, was presented by Stanislas Leibler (Rockefeller University, New York, USA) and Kenzie MacIsaac (University of Toronto, Canada). Regulatory circuits were created by coupling well-characterized inducible promoters (such as those controlled by IPTG or arabinose) to repressor proteins. Leibler emphasized that there is rarely a one-to-one relationship between the observed phenotypic characteristics of a system and hypotheses about the underlying genetic regulatory circuit: in the absence of detailed measurements, even three-gene systems can lead to results open to multiple interpretations. In short, the analysis of large gene networks cannot be conclusive with current data.<br>
At the other extreme of complexity, several groups presented a second approach: models for the entire regulatory network of yeast. David Gifford (Massachusetts Institute of Technology, Boston, USA) described the modeling of functional gene modules (sets of co-regulated genes) using Young's ChIP-on-chip data supplemented by gene-expression data. The genes in the identified modules contained similar promoter sequences, and their expression profiles correlated significantly. Subsequent comparison of the expression of genes in the modules with the transcription factors regulating them meant that the factors could be classified into activators and repressors. The idea of using co-expression data as a tool to define regulatory regions was also the basis of the closing keynote talk by Stuart Kim (Stanford University Medical Center, USA). He has analyzed data from human, fly, worm and yeast microarrays to identify groups of genes that are co-expressed in more than one species.<br>
As well as the use of phylogenetic footprinting in the detection of regulatory regions in genomic sequences, the same technique has been applied to detect evolutionarily conserved regulatory networks in yeast (Saeed Tavazoie, Princeton University, USA) and bacteria (poster presented by W.A.). Tavazoie demonstrated that the false-positive rate of binding-site predictions derived from yeast gene-expression data can be reduced if the data are filtered by analyzing the conservation of networks across related organisms.<br>
Innovative genomic methods to probe transcriptional regulation have helped to fulfil the promise of the techniques established in the early years of bioinformatics - phylogenetic footprinting, transcription-factor binding-site profiling and the identification of regulatory modules of binding sites. Algorithms are now emerging that can reveal critical information about the regulatory mechanisms governing expression of sets of genes. It was apparent from many presentations, however, that one challenge for the short term is to produce reliable reference collections of transcription-factor binding sites that can be used for the training and benchmarking of methods for the analysis of regulatory sequences. The current lack of such reference data results in an over-reliance on anecdotal evidence to justify methods: a surprising proportion of the methods presented at the meeting were justified by observations that a selected portion of the results agree with information found in the biological literature.<br>
Taken together, the impressive results shown at this meeting raise optimism for the future. Investigators may now wish to venture into new challenging areas: for instance, despite success in the analysis of yeast regulatory sequences, attempts to find the control sequences for co-expressed sets of human genes have rarely been fruitful. Alternatively, researchers may wish to respond to Stormo's challenge to decipher the amino-acid:nucleotide interaction code, or they may venture into the study of chromatin. The combination of new data resources and algorithmic advances is fueling real and meaningful progress in making sense of the mechanisms governing gene expression.<br>
<br>
<br>
<br>
<p><hr><p>

<b>PMC1868933</b><br>
Sense-antisense pairs in mammals: functional and evolutionary considerations<br>
Analysis of a catalog of S-AS pairs in the human and mouse genomes revealed several putative roles for natural antisense transcripts and showed that some are artifacts of cDNA library construction.<br>
<br>
Background<br>
Natural antisense RNAs (or natural antisense transcripts (NATs)) are endogenous transcripts with sequence complementarity to other transcripts. There are two types of NATs in eukaryotic genomes: cis-encoded antisense NATs, which are transcribed from the opposite strand of the same genomic locus as the sense RNA and have a long (or perfect) overlap with the sense transcripts; and trans-encoded antisense NATs, which are transcribed from a different genomic locus of the sense RNA and have a short (or imperfect) overlap with the sense transcripts. Cis-NATs are usually related in a one-to-one fashion to the sense transcript, whereas a single trans-NAT may target several sense transcripts [1-3]. In this manuscript, we describe analyses in which only cis-NATs were considered. From now on, we refer to these loci as sense-antisense (S-AS) pairs.<br>
When evaluated globally, several features related to the distribution of NATs strongly suggest they have a prominent role in antisense regulation in gene expression [4-7]. For instance, expression of S-AS transcripts tends to be positively or negatively correlated and is more evolutionarily conserved than expected by chance [4,5,7]. Although experimental validation of a putative regulatory role has been achieved for a few models [8-10], it is still unknown whether antisense regulation is a rule or an exception in the human genome. NATs have been implicated in RNA and translational interference [11], genomic imprinting [12], transcriptional interference [13], X-inactivation [14], alternative splicing [10,15] and RNA editing [16]. Moreover, an accumulating body of evidence suggests that NATs might have a pivotal role in a range of human diseases [2].<br>
NATs were initially identified in studies looking at individual genes. However, with the accumulation of whole genome and expressed sequences (mRNA and ESTs) in public databases, a significant number of NATs has been identified using computational analysis [17-22]. These studies showed a widespread occurrence of these transcripts in mammalian genomes. The first evidence that antisense transcription is a common feature of mammalian genomes came from analysis of reverse complementarity between all available mRNA sequences [17]. Subsequent studies, using larger collections of mRNA sequences, ESTs and genomic sequences, confirmed and extended these initial observations [18-22]. More recently, other sources of expression data, such as serial analysis of gene expression (SAGE) tags, were used to expand the catalog of NATs present in mammalian genomes [23,24]. At present, it is estimated that at least 15% and 20% of mouse and human transcripts, respectively, might form S-AS pairs [18,22], although a recent analysis [25] reported that 47% of human transcriptional units are involved in S-AS pairing (24.7% and 22.7% corresponding to S-AS pairs with exon and non-exon overlapping, respectively).<br>
The major obstacle in using expressed sequence data for NAT identification is how to determine the correct orientation of the sequences, especially ESTs. Many ESTs were not directionally cloned and even well-known mRNA sequences were registered from both strands of cloned cDNAs or are incorrectly annotated. As done by others [18,22,23], we here established a set of stringent criteria, including the orientation of splicing sites, the presence of poly-A signal and tail as well as sequence annotation, to determine the correct orientation of each transcript relative to the genomic sequence and made a deep survey of NAT distribution in the human and mouse genomes. Using a set of computational and experimental procedures, we extensively explored expressed sequences and massively parallel signature sequencing (MPSS) data mapped onto the human and mouse genomes. Besides generating a catalog of known and new S-AS pairs, our analyses shed some light on functional and evolutionary aspects of S-AS pairs in mammalian genomes.<br>
<br>
Results and discussion<br>
Overall distribution of S-AS pairs in human and mouse genomes<br>
To identify transcripts that derive from opposite strands of the same locus, we used a modified version of an in-house knowledgebase previously described for humans [26-28]. This knowledgebase contains more than 6 million expressed sequences mapped onto the human genome sequence and clustered in approximately 111,000 groups. Furthermore, SAGE [29] and MPSS [30] tags were also annotated with all associated information, such as tag frequency, library source and tag-to-gene-assignment (using a strategy developed by us for <software>SAGE Genie</software> [31]). An equivalent knowledgebase was built for the mouse genome (for more details see Materials and methods).<br>
We first designed software that searched the human and mouse genomes extracting gene information from transcripts mapped onto opposite strands of the same locus. Several parameters were used by the software to identify S-AS pairs, such as: sequence orientation given by the respective <database>GenBank</database> entry; presence and orientation of splice site consensus; and presence of a poly-A tail (for more details see Materials and methods). We found 3,113 and 2,599 S-AS pairs in human and mouse genomes, respectively, containing at least one full-insert cDNA (sequences annotated as 'mRNA' in <database>GenBank</database> and referred to here as such) in each orientation (Table 1). Furthermore, we also made use of EST data from both species. A critical issue when using ESTs is the orientation of the sequence, a feature not always available in the respective <database>GenBank</database> entries. We overcame this problem by simply using those ESTs that had a poly-A tail or spanned an intron and, therefore, disclosed their strand of origin by the orientation of a splicing consensus sequence (GT...AG rule). We found 6,964 and 5,492 additional S-AS pairs when EST data were incorporated into the analysis, totaling 10,077 and 8,091 pairs for human and mouse genomes, respectively (Table 1). All of these pairs contained at least one mRNA since we did not analyze EST/EST pairs. It is important to note that we haven't considered in the present analysis non-polyadenylated transcripts and trans-NATs. Thus, the total number of NATs is likely to be even higher in both genomes. Data presented in Table 1 are split in cases where a single S-AS pair is present in a given locus (single bidirectional transcription) and in cases where more than one pair is present per locus (multiple bidirectional transcription). Additional data file 1 lists two representative <database>GenBank</database> entries for all S-AS pairs split by chromosome mapping in the two species. As previously observed [17], S-AS pairs are under-represented in the sex chromosomes of both species (Additional data file 2).<br>
The above numbers confirm that S-AS pairs are much more frequent in mammalian genomes than originally estimated [4,17,18]. Our analyses suggest that at least 21,000 human and 16,000 mouse genes are involved in S-AS pairing. These numbers are more in agreement with those from [32] in their analysis using tiling microarrays to evaluate gene expression of a fraction of the human genome. For the mouse genome, our numbers are in agreement with those reported by Katayama et al. [8]. A more recent analysis [25] also gives a similar estimate of S-AS pairs in both human and mouse genomes.<br>
Could this high number of S-AS pairs be due to the stringency of our clustering strategy? If the same transcriptional unit is fragmented in close contigs due to 3' untranslated region (UTR) heterogeneity, the total number of clusters would be inflated, leading to an erroneous count of S-AS pairs. To evaluate this possibility, we relaxed our clustering parameters, requiring a minimum of 1 base-pair (bp) same strand overlap for clustering. Furthermore, we collapsed into a single cluster all pairs of clusters located in the same strand and less than 30 bp away from each other. Additional data file 3 shows the total number of clusters and S-AS pairs after this new clustering strategy was employed. As expected, both the total number of clusters and S-AS pairs decreased with the new clustering methodology. The total number of clusters decreased by 2% and 1% for human and mouse, respectively, while the total number of S-AS pairs decreased by 0.3% for both human and mouse. Thus, the small difference observed does not affect the conclusions on the genomic organization of S-AS pairs. For all further analyses, we decided to use the original dataset obtained with a more stringent clustering methodology.<br>
We further explored the genomic organization of S-AS pairs using the subset of 3,113 human and 2,599 mouse pairs that contained mRNAs in both sense and antisense orientations. The genomic organization of S-AS pairs can be further divided into three subtypes based on their overlapping patterns: head-head (5'5'), tail-tail (3'3') or embedded (one gene contained entirely within the other) pairs (Table 2). For a schematic view of the genomic organization of S-AS pairs, see Additional data file 4. Embedded pairs are more frequent in both species, corresponding to 47.8% and 42.5% of all pairs in human and mouse, respectively. If we take into account the intron/exon organization of both genes, we observe that the most frequent overlap involves at least one exon-intron border. In spite of this, a significant amount of NATs maps completely within introns from the sense gene in both human and mouse (category 'Fully intronic' in Table 2). Interestingly, more than three-quarters of all S-AS pairs categorized as 'Fully intronic' fall within the embedded category for human and mouse. How unique is this distribution? Monte Carlo simulations, in which we randomly replaced NATs in relation to sense genes while keeping their 5'5'/embedded/3'3' orientation, show that the distribution of S-AS pairs is quite unique. All three categories of S-AS pairs deviate from a random distribution (chi-square = 11.5, df (degrees of freedom) = 2, p = 0.003 for embedded pairs; chi-square = 49, df = 2, p = 2.3 ? 10-11 for 5'5' pairs; chi-square = 132, df = 2, p = 2.1 ? 10-29 for 3'3' pairs). This peculiar distribution will be further discussed in the light of the expression analyses. Since these intronic NATs have been shown to be over-expressed in prostate tumors [33], our dataset should be further explored regarding differential expression in cancer. Due to their genomic distribution, any putative regulatory role of these intronic NATs would have to be restricted to the nucleus. Interestingly, Kiyosawa et al. [34] observed that a significant amount of NATs in mouse is poly-A negative and nuclear localized.<br>
Another interesting observation is the higher frequency of intronless genes within the set of S-AS pairs (Table 3). About half (47%) of all mRNA/mRNA S-AS pairs in humans contains at least one intronless gene. This number is slightly lower for mouse (44%) (Table 3). Interestingly, intronless genes are significantly enriched within the set of embedded pairs (chi-square = 95.9, p &lt; 1.2 ? 10-22 for human and chi-square = 3.98 and p &lt; 0.045 for mouse). For humans, 66% of all S-AS pairs containing at least one intronless gene are within the 'embedded' category; Sun et al. [5] found 43.4% of their S-AS pairs as 'embedded'. Furthermore, they found 35% of 3'3' pairs while we found only 25%. These differences are probably due to the fact that Sun et al. [5] included in their analyses pairs containing only ESTs.<br>
All these results clearly show that subsets of S-AS pairs have distinct genomic organization, suggesting that they may play different biological roles in mammalian genomes. Below we will discuss these data in a functional/evolutionary context.<br>
<br>
Conservation of S-AS pairs between human and mouse<br>
Using our set of human and mouse S-AS pairs, we measured the degree of conservation between S-AS pairs from human and mouse. Since the numbers reported so far are discrepant, ranging from a few hundred [5,6] to almost a thousand [25], we decided to use different strategies. We first used a strategy based on <database>HomoloGene</database> [35]. The number of S-AS pairs with both genes mapped to <database>HomoloGene</database> is 854 for human and 579 for mouse. Among these, 190 S-AS pairs are conserved between human and mouse. One problem with this type of analysis lies in its dependence on <database>HomoloGene</database>, which, for example, does not take into consideration genes that do not code for proteins. Therefore, we decided to implement a different strategy, in which we identified those pairs that had at least one conserved gene mapped by <database>HomoloGene</database> and tested each known gene's NAT for sequence level conservation. Using this strategy, we found an additional 546 cases, giving a total of 736 (190 + 546) conserved S-AS pairs between human and mouse. Finally, we also applied to our dataset the same strategy used by Engstrom et al. [25], in which they counted the number of human and mouse S-AS pairs that had exon overlap in corresponding positions in a <software>BLASTZ</software> alignment of the two genomes. We applied the same strategy to our dataset and found 1,136 and 1,144 corresponding S-AS pairs in human and mouse, respectively. As observed by Engstrom et al. [25] the numbers from human and mouse slightly differ because a small proportion of mouse pairs corresponded to several human pairs and vice versa. Additional data file 5 lists all S-AS pairs found by the three methodologies discussed above.<br>
There is a predominance of 3'3' pairs in all sets of conserved S-AS pairs. For the first strategy solely based on <database>HomoloGene</database>, 67% of all pairs are 3'3' compared to 19% embedded and 14% 5'5'. For the dataset obtained using the strategy from Engstrom et al. [25], there is also a prevalence of 3'3'pairs (48%) compared to embedded (14%) and 5'5 (38%) pairs. We have also modified the method of Engstrom et al. [25] to take into account all S-AS pairs and not only those presenting exon-exon overlap. These data are shown in Additional Data File 6. We observed that S-AS pairs whose overlap is classified as 'Fully intronic' are less represented in the set of conserved S-AS pairs (18% in this set compared to 29% in the whole dataset of S-AS pairs). The same is true for S-AS pairs containing at least one intronless gene (26% in the set of conserved S-AS pairs compared to 47% in the whole dataset). These last results are in accordance with our previous observation that conserved S-AS pairs are enriched with 3'3' pairs. As seen in Tables 2 and 3, 3'3' pairs are poorly represented in the categories 'Fully intronic' (Table 2) and 'Intron/intronless' (Table 3).<br>
<br>
Discovery of new S-AS pairs in human and mouse genomes using MPSS data<br>
Large-scale expression profiling tools have been used to discover and analyze the co-expression of S-AS pairs [5,23,34]. Qu?r? et al. [23], for instance, recently explored the SAGE repositories to detect NATs. These authors searched for tags mapped on the reverse complement of known transcripts and analyzed their expression pattern on different SAGE libraries. However, no attempt was made to experimentally validate the existence of such NATs. Here, we made use of MPSS data available in public repositories [36,37] to search for new NATs in both human and mouse genomes. Since MPSS tags are longer than conventional SAGE tags, we can use the genome sequence for tag mapping. Furthermore, MPSS offers a much deeper coverage of the transcriptome since at least a million tags are generated from each sample.<br>
We made use of 122 MPSS libraries derived from a variety of human and mouse tissues (81 libraries for mouse, 41 for human; see the list in Additional data file 7). Our strategy was based on the generation of virtual tags from each genome by simply searching the respective genome sequence for DpnII sites. Since these sites are palindromes, we extract, for each one, two virtual tags (13 and 16 nucleotide long tags for human and mouse, respectively), both immediately downstream of the restriction site but in opposite orientations (see Materials and methods for more details). In this way, we could evaluate the expression of transcriptional units present in both strands of DNA. We obtained 5,580,158 and 8,645,994 virtual tags for the human and mouse genomes, respectively. This set of virtual tags was then compared to a list of tags observed in the MPSS libraries. As true for any study using mapped tags, our analysis misses those cases in which a tag maps exactly at an exon/exon border at the cDNA level.<br>
We first evaluated the number of cDNA-based S-AS pairs (shown in Table 1) that were further confirmed by the presence of an MPSS tag. Data for this analysis are presented as Additional data file 8. Roughly, 84% and 51% of all cDNA-based S-AS pairs were confirmed by MPSS data for human and mouse, respectively.<br>
Since we were interested in finding new antisense transcripts, we searched for tags found in the MPSS libraries that were mapped on the opposite strand of both introns and exons of known genes. For this analysis we excluded those genes that were already part of S-AS pairs as described above. For humans, 4,308 genes have at least one MPSS tag derived from the antisense strand (Table 4). For 1,221 human genes there were two or more distinct MPSS tags in the antisense orientation. Another interesting observation is the larger number of MPSS tags antisense to exonic regions of the sense genes. Unexpectedly, we found a much smaller number of antisense tags for mouse (Table 4). Although the number of mouse libraries is larger (81 mouse and 41 human libraries), the number of unique tags is significantly smaller (56,061 for mouse and 340,820 for human). The assignment of these unique tags to known genes shows a smaller representation of known genes in the mouse dataset (51% against 66% for human). It is unlikely, however, that these differences can explain the dramatic difference shown in Table 4. Further analyses are needed to solve this apparent discrepancy.<br>
To experimentally validate the existence of these novel human NAT candidates we used the GLGI (Generation of Longer cDNA fragments from SAGE for Gene Identification)-MPSS technique [38] to convert 96 antisense MPSS tags into their corresponding 3' cDNA fragments. A sense primer corresponding to the antisense MPSS tag was used for GLGI-MPSS amplification as described in Materials and methods. A predominant band was obtained for most of the GLGI-MPSS reactions (Figure 1). Amplified fragments were purified, cloned, sequenced and aligned to the human genome sequence. We were able to generate a specific 3' cDNA fragment for 46 (50.5%) out of 91 novel antisense candidates. Of these 46, the poly-A tail of 19 aligned with stretches of As in the human genome sequence (this finding will be discussed further). The existence of three of these antisense transcripts, out of three that were tested, was further confirmed by orientation-specific RT-PCR (data not shown).<br>
Among the 49.5% (91 - 46 = 45) of candidates that were not considered to be validated, we found 25 that were amplified in the GLGI-MPSS experiment but whose exon-intron organization was identical to the sense gene. Although antisense sequences like these have already been observed [39], we did not consider them as validated antisense transcripts. Orientation-specific RT-PCR confirmed the existence of one transcript, out of two that were tested.<br>
<br>
Alternative polyadenylation as a major factor in defining S-AS pairs<br>
Dahary et al. [6] observed that S-AS overlap usually involves transcripts generated by alternative polyadenylation. This observation had already been reported by us and others [40]. We decided to test if these preliminary observations would survive a more quantitative analysis. We found that the S-AS overlap is predominantly due to alternative polyadenylation variants. Roughly, 51% of all S-AS pairs (274 out of 533 3'3' pairs) overlap due to the existence of at least one variant. This number is certainly underestimated since many variants are still not represented in the sequence databases. The above observation raises the exciting possibility that antisense regulation is associated with the regulation of alternative polyadenylation. It is expected that the presence of overlapping genes imposes constraints on their evolution since any mutation will be evaluated by natural selection according to its effect in both genes. Thus, in principle, overlapping genes should impose a negative effect on the fitness of a subject. Alternative polyadenylation has the potential to relax such negative selection since the overlapping is dependent on a post-transcriptional modification.<br>
If alternative polyadenylation is a significant factor in defining S-AS pairs, we would expect a lower rate of alternative polyadenylation in chromosome X, which has the smallest density of S-AS pairs. Indeed, only 20% of all messages from the X chromosome show at least two polyadenylation variants, compared to 27.5%, on average, for the autosomes (chi-square = 34.91, df = 1, p &lt; 0.0001).<br>
<br>
A fraction of S-AS pairs is generated through internal priming and retroposition events<br>
During the validation of new NATs identified using the MPSS data, we noticed that a significant fraction of GLGI amplicons (19 out of 46 validated fragments) had their 3' ends aligning to stretches of As in the human genome. This motivated us to search for similar cases in the set of cDNA-based S-AS pairs identified in this study. We found that 18% and 26% of all S-AS pairs have at least one gene with its 3' end aligning with a stretch of A's in the human and mouse genomes, respectively. This number is certainly inflated by ESTs since it decreases to 11.7% for human and 12.6% for mouse when only mRNA/mRNA S-AS pairs are considered. Two possibilities could account for this observation. First, a fraction of all antisense transcripts would be artifacts due to genomic priming with contaminant genomic DNA during cDNA library construction. An alternative is the possibility that antisense genes were constructed during evolution by retroposition events. Both possibilities are in agreement with the observation that antisense genes are depleted of introns.<br>
An experimental strategy was developed to evaluate the likelihood of genomic priming as a factor generating artifactual antisense cDNAs. A total of 11 mRNA candidates derived from cDNA libraries from fetal liver, colon and lung with a high proportion of sequences that had their 3' ends aligning to stretches of As in the human genome were selected for experimental validation by RT-PCR. cDNA samples used in these experiments were reverse transcribed from fetal liver, colon and lung total RNA treated or not with DNAse. As can be seen in Figure 2, specific amplifications could not be achieved for 7 (63.6%) out of the 11 selected candidates when cDNA samples used as templates for PCR amplification were prepared from DNA-free RNA. On the other hand, when untreated RNA was used for cDNA synthesis, all candidates could be amplified, suggesting that a significant proportion of these internal priming sequences were indeed generated from contaminant genomic DNA.<br>
Some other features support the artifactual origin of these antisense transcripts. First, cDNAs containing a stretch of As at their 3' genomic end have much less polyadenylation signals than genes in general (17% compared to 85%). Furthermore, these genes have a much narrower and rarer expression pattern when analyzed by SAGE and MPSS than genes in general (data not shown). These observations suggest that a significant fraction of all antisense genes are actually artifacts, due to genomic priming during library construction.<br>
Retroposition generates intronless copies of existing genes through reverse transcription of mature mRNAs followed by integration of the resulting cDNA into the genome (for a review, see Long et al. [41]). Eventually, the cDNA copy can be involved in homologous recombination with the original source gene as has been suggested for yeast [42]. Retroposition was thought to generate non-functional copies of functional genes. However, several groups have shown that retroposition has generated a significant amount of new functional genes in several species [43-45]. Recently, Marques et al. [43] found almost 4,000 retrocopies of functional genes in the human genome. More recently, the same group reported that more than 1,000 of these retrocopies are transcribed, of which at least 120 have evolved as bona fide genes [46].<br>
Retrocopies usually have a poly-A tail at their 3' end because of the insertion of this post-transcriptional modification together with the remaining cDNA. Thus, retroposition can explain the high incidence of antisense transcripts with a poly-A tail at their 3' end. To evaluate the contribution of retrocopies to the formation of S-AS pairs we compared the loci identified by Marques et al. [43] as retrocopies with the list of S-AS pairs identified in this study. Out of 413 retrocopies represented in the cDNA databases, 138 were involved in S-AS pairs (70 mRNA/mRNA and 68 mRNA/EST pairs). For the 70 mRNA/mRNA pairs, 78% were classified as embedded. This is in agreement with our previous observation that embedded pairs are enriched with intronless genes. Thus, retroposition seems to significantly contribute to the origin of embedded S-AS pairs.<br>
<br>
Expression patterns within S-AS pairs<br>
A critical issue to effectively evaluate the role of antisense transcripts in regulating distinct cellular phenomena is related to the expression pattern of both sense and antisense transcripts belonging to the same S-AS pair. Several reports have been published based on large-scale gene-expression analyses [5,19,23,47,48]. Similar to Wang et al. [48], we here used MPSS libraries available for human to explore this issue. Tag to gene assignment was performed as previously described [31,49]. To ensure the MPSS sequences were unambiguously matched to the assigned transcript, we removed tags mapped to more than one locus. Frequencies for all tags assigned to genes in an S-AS pair were collected from all MPSS libraries.<br>
Figure 3 shows the expression pattern of S-AS pairs for all MPSS libraries for human. We divided the dataset into the following categories as before: 3'3', 5'5' or embedded. Several features are evident. The rate of co-expression in our dataset was 35.1% compared to 44.9% observed by Chen et al. [4]. The differences are probably due to experiment design in both reports (for example, differences in the dataset and in the way the rate was calculated). Second, the rate of co-expression is significantly higher for 3'3' pairs when compared to the frequency of the embedded pairs (50.3%, chi-square = 134, df = 1, p = 5.4 ? 10-31). This supports a previous conclusion from Sun et al. [5] that 3'3' S-AS pairs are significantly more co-expressed than other pairs and, therefore, are more prone to be involved in antisense regulation. It is important to mention that 5'5' pairs are also enriched in co-expressed pairs when compared to embedded pairs (chi-square = 23.5, df = 1, p = 1.2 ? 10-6). We observed no statistical difference among the three categories regarding differential expression of both genes in a pair.<br>
<br>
Influence of antisense transcripts in the splicing of sense transcripts<br>
It is quite clear nowadays that a significant fraction of all human genes undergo regulated alternative splicing, producing more than one mature mRNA from a gene (Galante et al. [27] and references therein). Although several regulatory elements in cis and trans have been identified (for a review see Pagani and Baralle [50]), it is reasonable to say that we are far from a complete understanding of how constitutive and alternative splicing are regulated. One possible regulatory mechanism involves antisense sequences. Since the late 1980s, it is known that antisense RNA can inhibit splicing of a pre-mRNA in vitro [15]. A few years later, Munroe and Lazar [51] observed that NATs could inhibit the splicing of a message derived from the other DNA strand, more specifically the ErbA? gene. More recently, Yan et al. [52] characterized a new human gene, called SAF, which is transcribed from the opposite strand of the FAS gene. Over-expression of SAF altered the splicing pattern of FAS in a regulated way, suggesting that SAF controls the splicing of FAS. With the growing amount of genomic loci presenting both sense and antisense transcripts, a general role for S-AS pairing in splicing regulation has been proposed [47]. However, no systematic large-scale analysis has been reported so far investigating this issue for mammals. We made use of the human dataset described in this report to tackle this problem.<br>
We first tested whether the rate of alternative splicing in the sense gene would be affected by the existence of an antisense transcript. It is expected that the effect of S-AS pairing on splicing would be restricted to those exon-intron borders located in the region involved in pairing. We therefore restricted the analysis to those exon-intron borders spanning the region involved in an S-AS pairing. Our strategy was to compare the number of splicing variants for those borders against all other exon-intron borders (those without an antisense transcript) in the same genes. To make the analysis more informative we split the borders into four categories (terminal donor, internal donor, internal acceptor and terminal acceptor). For both internal donor and acceptor sites, the presence of an antisense transcript slightly increased the rate of alternative splicing (Table 5; 4% and 3% increases, respectively). For the terminal sites, the presence of a NAT had the opposite effect (5% and 6% decrease for donor and acceptor, respectively). Table 5 also shows that these differences are predominantly due to intron retention. On the other hand, NATs located within the introns and exons (but not spanning the border) have no major effect on the splicing of the respective borders. The observed differences between borders with or without NATs is statistically significant (chi-square = 31.2, df = 1, p = 2.3 ? 10-8 for donor sites; and chi-square = 23, df = 1, p = 1.6 ? 10-6 for acceptor sites).<br>
Recently, Wiemann et al. [53] reported a new variant of IL4L1 that contains the first two exons of an upstream gene, NUP62. This chimeric transcript was expressed in a tissue and cell-specific manner. The authors speculated that cell type specific alternative splicing was involved in the generation of this chimeric transcript. We speculate that NATs could be involved in the generation of this type of chimeric cDNA. The same antisense message pairing with both sense messages would form a double-stranded RNA that could induce the spliceosome to skip the paired region and join the two sense messages, a process very similar to the one proposed for trans-splicing in mammals [54]. Interestingly, we found five examples in our dataset of S-AS pairs in which the genomic organization of both sense and antisense genes suggest a process like this. Additional data file 9 illustrates one of these cases. It can be seen that two transcripts represented by cDNAs AK095876 and AK000438 join messages from genes SERF2 and HYPK. The antisense transcript is represented by cDNA AK097682. Additional data file 10 lists all other putative cases of chimeric transcripts. The fact that both sense genes share a common antisense transcript raises the possibility that antisense transcripts can mediate trans-splicing of the sense genes, thereby generating the chimeric transcript.<br>
<br>
On the evolution of S-AS pairs: functional implications<br>
It is reasonable to assume that a fraction of all S-AS pairs reached this genome organization solely by chance. However, evidence presented here and elsewhere suggest that this fraction is probably small [6,55,56]. For example, Dahary et al. [6] concluded that antisense transcription had a significant effect on vertebrate genome evolution since the genomic organization of S-AS pairs is much more conserved than the organization of genes in general. However, how did this organization come to be? In principle, S-AS genomic organization should carry a negative effect on the overall fitness of a subject. For each gene in an S-AS pair, its evolution is constrained not only by features of its own sequence but also by functional features encoded by the other gene in the pair. The fact that we observed a significant amount of S-AS pairs in mammalian genomes suggests that there are advantages inherent to this organization to counter-balance the negative effects. The proposed role of NATs in gene regulation is certainly advantageous. We propose here two evolutionary scenarios, not mutually exclusive, that would speed up the generation of S-AS pairs. In one scenario, alternative polyadenylation has a fundamental role. Sun et al. [5] observed a preferential targeting of 3' UTRs for NATs. Our observation that 51% of 3'3' S-AS pairs overlap because of polyadenylation variants suggests that selection has favored cases where overlapping occurs only in a time and spatially regulated manner.<br>
In a second scenario, retroposition generates NATs, which lack introns and may even show a polyadenylation tail integrated into the genome. We observe here that retroposition contributed significantly to the origin of S-AS pairs, especially those classified as embedded. What would be the selective advantages of retrocopies as NATs? Chen et al. [56] observed that antisense genes have shorter introns when compared to genes in general. They speculated that this feature was advantageous during evolution since NATs need to be "rapid responsers" to execute their regulatory activities. Although transcription is a slow process in eukaryotes, another bottleneck in the expression of a gene is splicing. Furthermore, Nott et al. [57] observed that the presence of introns in a gene affects gene expression by enhancing mRNA accumulation. Thus, the argument from Chen et al. [56] gets stronger with the data reported here and by Nott et al. [57] since intronless antisense genes would be transcribed even faster; their transcripts would simply skip splicing and the half-life of the respective messages would be shorter. All key features for genes involved in regulatory activities.<br>
An important issue is the conservation of S-AS pairs between human and mouse. Although we found more than a thousand conserved pairs, this number is still small compared to the whole set of S-AS pairs in both species. Several factors, however, suggest that the number reported here is an underestimate. First, as discussed by Engstrom et al. [25], sequence conservation might not be of primary importance for antisense regulation. Furthermore, it is likely that many truly conserved pairs were not detected because transcript sequences have not been discovered yet. This is more critical in the face of our findings that a significant proportion of 3'3' S-AS pairs depend on alternative polyadenylation for an overlap. It is also quite likely that some S-AS pairs are lineage-specific. For instance, our finding that retroposition contributes to the origin of many S-AS pairs could explain the appearance of lineage-specific S-AS pairs, assuming that the retroposition event occurred after the divergence between human and mouse.<br>
These two evolutionary scenarios (alternative polyadenylation and retroposition) might produce S-AS pairs with different functional implications. The expression and evolutionary conservation analyses presented here, together with evidence from others [5,19,23,47,48] suggest that 3'3' overlap achieved by polyadenylation variants was used throughout evolution to regulate gene expression. Those pairs generated through retroposition may be involved in some other types of regulation, such as alternative splicing.<br>
<br>
<br>
Conclusion<br>
This is the deepest survey so far of S-AS pairs in the human and mouse genomes. We made use of all cDNAs available in the public domain together with 122 MPSS libraries for human and mouse. The major findings of the present report include: as many as 10,077 and 8,091 S-AS pairs were identified for human and mouse respectively; using MPSS data, we found 4,308 and 216 new putative S-AS loci in human and mouse, respectively; a small fraction of all S-AS pairs are artifacts caused by genomic priming during cDNA library construction; a significant amount of S-AS pairs is due to retroposition events of one of the genes in the pair; quantitative analyses suggest that the presence of an antisense gene, complementary to an exon-intron border of the sense gene, increases the rate of retention of the respective intron. Furthermore, we propose an evolutionary model in which alternative polyadenylation and retroposition are important forces in the generation of S-AS pairs.<br>
Taken together, these results offer, up to now, the vastest catalog of S-AS pairs in human and mouse genomes.<br>
<br>
Materials and methods<br>
Mapping cDNAs and MPSS tags onto the human and mouse genomes<br>
We used a modified protocol similar to the one described previously to identify transcription clusters in the human and mouse genomes [27,28]. Briefly, genome sequence (NCBI build no. 35 for human and NCBI build no. 33 for mouse), EST collections (5,992,459 sequences for human and 4,246,824 sequences for mouse) and mRNA sequences (186,358 for human and 120,058 for mouse) were downloaded from <database>UCSC</database> [58]. All cDNAs were mapped to the respective genome sequence using <software>BLAT</software> (default parameters) [59]. The best hit for each cDNA in the genome was identified, followed by a pairwise alignment using <software>Sim4</software> [60]. Only transcripts presenting identity ?94%, coverage ?50% and all splice sites in the same orientations were used.<br>
Correct orientation of ESTs was determined by the presence of a poly-A tail (a stretch of 8 As at the 3' end) and/or a splicing donor (GT) and acceptor (AG) sites. All mRNAs were considered in the 'sense' orientation (oriented from 5' end to 3' end). All cDNAs mapped and reliably orientated were assembled into clusters. One cluster contains cDNAs presenting the same orientation and sharing at least one exon-intron boundary or a minimum of 30 nucleotides of overlap (only for those sequences without a common exon/intron organization).<br>
For the mapping of MPSS data, we first extracted 'virtual' tags for both human and mouse genomes by simply finding all DpnII sites and extracting a 13 (human) or 16 (mouse) nucleotide long sequence immediately downstream of the restriction site in both orientations. These 'virtual' tags present only once in the respective genomes were further used and matched against the 'real' tags found in 41 and 81 MPSS libraries for human and mouse, respectively. Only MPSS tags classified as 'reliable' (present in more than one sequencing run) and 'significant' (tags per million &gt;3) were considered as trusted signatures.<br>
<br>
Identification of S-AS pairs<br>
S-AS pairs were identified as those cases in which two clusters, in opposite orientations, overlap at the genome level. For the correct orientation of all mapped cDNAs, we took into consideration several parameters, including: sequence annotation as available in the respective <database>GenBank</database> entry; splice junctions; and poly-A tails and poly-T heads. We excluded from our analyses all cDNAs that presented conflicting orientations as defined by the three criteria above. If only two clusters overlap in the opposite orientation, they were classified as a single bidirectional S-AS pair. If a given cluster overlaps with more than one antisense cluster, they were classified as multiple bidirectional S-AS pairs. S-AS pairs were also classified according to their genomic pattern. Parameters evaluated included: pattern of S-AS overlap (exonic, intronic and exonic/intronic); spanning of introns by the components of a pair as defined by their alignment onto the genome; and chromosome localization and relative orientation within the S-AS pairs (tail-tail, head-head and embedded).<br>
<br>
Conservation between human and mouse S-AS pairs<br>
We used three strategies to evaluate the degree of conservation between human and mouse S-AS pairs. First, all pairs were searched against the dataset from <database>HomoloGene</database> [35] and those pairs conserved in both species were counted. In our second strategy, we selected those S-AS pairs in which at least one gene was conserved according to <database>HomoloGene</database>. We then used Needle, an alignment algorithm [61], to test sequence conservation between the respective antisense genes. We classified as conserved those global alignments with identity &gt;30%. Finally, we also used the strategy from Engstrom et al. [25]. We used the net alignment between human and mouse genomes (retrieved from the <database>UCSC Genome Browser</database> database) to define the corresponding (synthenic) regions. We considered a human S-AS pair to be conserved in mouse if it had an exon region aligning (&gt;20 bp) to an exon region from a mouse pair.<br>
<br>
Investigation of the expression pattern of S-AS transcripts<br>
We evaluated the expression pattern of S-AS pairs at the whole genome level based on their expression profiles obtained from MPSS libraries (available at [36]). The procedure was previously described by us for SAGE and MPSS [27,31,49]. The tag to gene assignment was done by scanning and extracting virtual tags (13 nucleotide-long sequences present downstream to the 3'-most DpnII restriction sites of each mRNA sequence). To accurately represent the 3' end of a transcript, only mRNA sequences containing a poly-A tail were used. All tags mapped to two or more different genes were excluded and the frequencies of different tags for the same gene (mainly alternative polyadenylation variants) were summed. MPSS tags were normalized to counts-per-million and the expression data were cross-linked to genomic positions by the extraction of virtual tags for both the human and mouse genomes. Only tags showing 100% identity with a genomic locus were used in the analyses.<br>
The classification of the expression pattern of S-AS pairs was done using those tags with ?3 tags per million across all MPSS libraries. To evaluate the co-expression of all S-AS pairs, both genes in a pair had to be co-expressed in at least 04 libraries. If both genes in a pair were co-expressed in less than four libraries or they were independently expressed in different libraries, the pair was classified as 'single-gene expression'. The remaining S-AS pairs were classified as 'no-expression'.<br>
<br>
Identification of antisense MPSS tags<br>
All DpnII sites in the human and mouse genomes were identified and for each site two 'virtual' MPSS tags were extracted from both DNA strands in the correct orientation. All 'virtual' MPSS tags mapped in the opposite strand of known mRNAs in both genomes were identified. Those mRNAs belonging to an S-AS pair previously identified were excluded. Those antisense MPSS tags mapped just once in the respective genome and present in at least one MPSS library were identified and submitted to experimental validation.<br>
<br>
Simulations on the genomic organization of S-AS pairs<br>
A random distribution of S-AS pairs was obtained by re-indexing the coordinates of one gene in all the pairs 1,000 times. This was done by randomly selecting a genomic coordinate for the start of mapping of a given gene. All the remaining exon-intron borders were then re-indexed based on this initial coordinate. The relative organization of both genes in all random S-AS pairs was stored and frequencies for each category were calculated. Those frequencies were used as the expectation for chi-square tests of the null hypothesis.<br>
<br>
Identification of splicing variants<br>
Using the database mentioned earlier and described elsewhere [26-28] we identified all exon-intron borders complementary to a NAT. We then compared the rate of alternative splicing in these borders against the borders from the same genes without a NAT. We established a set of stringent criteria to identify alternative borders. These criteria are detailed elsewhere [26-28].<br>
<br>
Experimental validation of MPSS antisense tags<br>
MPSS tags corresponding to antisense transcripts were converted into their corresponding 3' cDNA fragments using GLGI-MPSS [37]. Antisense tags were selected from a MPSS library derived from the normal breast luminal epithelial cell line HB4a and the same RNA source was used for GLGI amplification. For the GLGI-MPSS amplification, we used a sense primer including 17 bases of the MPSS tag sequence and 6 additional bases (CAGGGA), giving a total of 23 bases for each primer (5'-CAGGGAGATCXXXXXXXXXXXXX-3'). We also used an antisense primer (ACTATCTAGAGCGGCCGCTT) present in the 3' end of all cDNA molecules that was incorporated from reverse transcription primers in cDNA synthesis. The reaction mixture was prepared in a final volume of 30 ?l, including 1? PCR buffer, 2.0 mM MgCl2, 83 ?M dNTPs, 2.3 ng/?l antisense primer, 2.3 ng/?l sense primer, 1.5 U of Taq Platinum DNA polymerase (Invitrogen, San Diego, CA, USA) and 0.5-0.8 ?l of the same cDNA source used for MPSS library construction. PCR conditions used for amplification were 94?C for 2 minutes, followed by 30 cycles at 94?C for 30 s, 64?C for 30 s, and 72?C for 35 s. Reactions were kept at 72?C for 5 minutes after the last cycle. The amplified products were ethanol precipitated and cloned into the pGEM?-T Easy vector (Promega, Madison, WI, USA). Twelve colonies for each GLGI-MPSS fragment were screened by PCR using pGEM universal primers and positive colonies were sequenced using Big-Dye Terminator (Applied Biosystems, Foster City, CA, USA) and an ABI3100 sequencer (Applied Biosystems).<br>
<br>
Experimental validation of genomic primed sequences<br>
Total RNA derived from fetal liver, colon and lung was purchased from Clontech laboratories (Palo Alto, CA, USA). For cDNA synthesis, 2 ?g of total RNA were treated (or not) with 100 units of DNAse I (FPLC-pure, Amersham, Piscataway, NJ, USA) and were reverse transcribed using oligo(dT)12-18, random primers and SuperScript II (Invitrogen), following the manufacturers' instructions. After synthesis, the resulting cDNA was subjected to RNase H treatment. The absence of genomic DNA contamination was evaluated for each preparation. DNA-free total RNA was subjected to PCR amplification using primers within intronic sequences flanking exon 12 of the hMLH-1 gene (forward, 5' TGGTGTCTCTAGTTCTGG3'; reverse 5' CATTGTTGTAGTAGCTCTGC 3'). All PCR amplifications were carried out using 2 ?l of cDNA as a template to the final volume of 25 ?l and 1? buffer, 1.5 mM MgCl2, 0.2 mM dNTP, 0.2 ?M of each specific primer and 0.025 U/?l of Taq DNA polymerase (Life Technologies, San Diego, CA, USA). The following cycling protocol was used: initial denaturation of 94?C for 4 minutes; 94?C for 30 s; 55?C for 45 s; 72?C for 1 minute for 35 cycles; along with a final extension at 72?C for 7 minutes. All PCR products were resolved on 8% polyacrylamide gels and sequenced as described above to verify amplification specificity.<br>
<br>
Strand-specific RT-PCR<br>
In the strand-specific RT-PCR, orientation of the transcript is accessed by restricting which gene-specific primer is present during first-strand cDNA synthesis. For each candidate, 1 ?g of total RNA was treated with Promega RQ1 RNAse-free DNAse and tested for remaining DNA contamination as described above. First-strand cDNA synthesis was carried out at 50?C for 2 h using 200 U of SuperScript II (Invitrogen) and 0.9 ?M of a primer complementary to the antisense transcript. PCR amplifications were performed using 1 ?l of the first-strand cDNA as a template in a final volume of 25 ?l and 1? buffer, 1.5 mM MgCl2, 0.1 mM dNTP, 0.4 ?M of gene specific primers and 1 U of Platinum Taq DNA polymerase (Invitrogen). The following cycling conditions were used for amplification: initial denaturation of 95?C for 2 minutes; 94?C for 40 s; reaction-specific annealing temperature for 40 s and 72?C for 1 minute for 35 cycles; followed by a final extension step at 72?C for 7 minutes. All PCR products were resolved on 8% polyacrylamide gels. Controls for the absence of self-priming during cDNA synthesis were done with reverse transcriptase in the absence of primers, and controls for the absence of DNA were done by incubation with primers but with no reverse transcriptase.<br>
<br>
Availability<br>
To make our dataset fully accessible to the community we have set up a worldwide web portal [62] containing all raw data generated in this study and a series of tools to explore the data.<br>
<br>
<br>
Additional data files<br>
The following additional data are available with the online version of this paper. Additional data file 1 is a list of representative <database>GenBank</database> entries for all S-AS pairs in both human and mouse. Additional data file 2 is a table showing the total number of S-AS pairs by chromosome for both human and mouse. Additional data file 3 shows the number of clusters and S-AS pairs when a less stringent clustering methodology is applied. Additional data file 4 shows a schematic view of all possible genomic organizations of S-AS pairs. Additional data file 5 lists all S-AS pairs conserved between human and mouse using the three strategies described in the text. Additional data file 6 shows the fraction of S-AS pairs conserved between human and mouse that are classified as 'Fully intronic' and the fraction of conserved S-AS pairs that contain at least one intronless gene. Additional data file 7 is a list of all MPSS libraries used in this study. Additional data file 8 presents the number of cDNA-based pairs that were further confirmed by the MPSS data. Additional data file 9 is a figure illustrating chimeric transcripts joining two adjacent genes (SERF2 and HYPK) with a NAT located between them. Additional file 10 lists all cases of chimeric transcripts identified in our dataset.<br>
<br>
Supplementary Material<br>
<br>
<br>
<br>
<p><hr><p>

<b>PMC463070</b><br>
Genomic, chromosomal and allelic assessment of the amazing diversity of maize<br>
A report on the 46th Annual Maize Genetics Conference, Mexico City, Mexico, 11-14 March 2004.<br>
<br>
<br>
Teosinte thrived in the highlands and valleys of central Mexico 8,000 years ago. Human selection for increased seed number, cob size, poor seed dispersal, and nutritional value domesticated this wild plant into what we recognize today as maize. The 2004 Maize Genetics Conference was the first to be held near the site of the origin of maize and the present-day center of species diversity, and questions about the origin, types and consequences of maize diversity were central to the 42 talks and nearly 200 poster presentations. A starlight tour of the Museo Nacional de Antropolog?a  allowed delegates to examine the depiction of corn by successive pre-colonial Mexican civilizations for further inspiration.<br>
<br>
Modern maize captured the genetic diversity of teosinte<br>
Ed Buckler (USDA-ARS at Cornell University, Ithaca, USA) has analyzed maize diversity by sequencing 18 genes, in toto or in part, from more than 100 inbred lines. As a benchmark consider that humans have about 0.09% base substitution in pair-wise comparisons and that as a species we are 1.34% different from chimpanzees. Evaluating pairs of modern inbred lines of maize, previous work has shown that there is 1.42% silent diversity in coding regions! In a typical gene there are between 20 and 25 amino-acid polymorphisms among alleles: 30% are radical changes and a further 22% are 'indel' mutations of missing or added amino acids. This tremendous diversity in maize reflects the maintenance of genetic differences from teosinte: domestication did not involve a bottleneck with a handful of representative alleles; rather, present-day corn has alleles that have been filtered by selection over millions of years. Buckler estimated that a single family gathering teosinte seed to supply 10% of their calories would have required 300,000 plants. The several million people of ancient Mexico at the onset of maize domestication probably used seed from teosinte populations of several billions of plants at all stages of domestication. In contrast, only a few tomato or pepper plants suffice in a kitchen, and the domesticated types exhibit correspondingly low genetic diversity.<br>
Using diverse alleles, association genetics can pinpoint which polymorphisms confer specific phenotypes. To avoid false assignments between genotype and phenotype, a robust knowledge of population structure in maize lines allows line history to be separated from independent genetic changes that confer plant properties. Buckler's group and others have further established that linkage disequilibrium (LD), a measure of the recombinational history of chromosomal regions, decays within 1 kilobase (kb) for landraces (traditional varieties grown by subsistence farmers), within 2 kb for modern maize inbred lines used by geneticists, and in roughly 2-20 kb in the elite commercial inbred lines developed in the past decades for the hybrid corn seed industry. For loci with a major impact on productivity and plant architecture, ancient and modern plant breeders have applied stringent selection, and in these cases LD expands to cover a larger region and the drop in allele diversity can be used to link quantitative trait loci (QTLs) to genie regions likely to be important in domestication and yield. For example, four of six genes in the starch biosynthesis pathway show a significant decrease in allele diversity compared to only 5% of randomly selected loci. Recently published work from Buckler and collaborators describes an analysis of ancient maize specimens and showed that particular alleles of Teosinte branched1, which encodes a modulator of stem and floral architecture, and Pbf, encoding a regulator of seed storage protein, were fixed about 4,000 years ago in domesticated maize, whereas favorable alleles of Sugary1, key to producing sweet corn, were not selected in the corn grown in the southwestern USA until approximately 1,000 years ago.<br>
And what has been the fate of teosinte? Jerry Kermicle (University of Wisconsin, Madison, USA) illustrated that it grows robustly in uncultivated areas, and as a weed in Mexican cornfields, often mimicking the morphology of modern maize so closely that farmers cannot recognize it. How does teosinte persist if it is interfertile with domesticated maize? Kermicle explained that haploid maize pollen performs poorly on teosinte silks, where many centimeters separate pollen attachment and the individual ovules on the ear. Teosinte carries dominant alleles of the Gametophyte factor1 (Ga1) locus that confer preferential growth on a Ga1 silk; in contrast, modern corn is ga1 and this pollen is only 1% as successful on teosinte Ga1 silks. This 'trick' is employed commercially to permit selective pollination within small blocks of sweet corn or popcorn despite the billions of wind-borne pollen grains from nearby standard corn. Ga1 alone cannot explain the crossing barrier between teosinte and corn, however, because Mexican landraces of corn carry the Ga1-male acting allele that is compatible with Ga1 teosinte silks. Kermicle reported a second gene, Teosinte crossing barrier1 (Tcb1), that reduces inter-crossing many-fold by restricting pollen with the recessive tcb1 allele from growing on Tcb1 teosinte silks. Interestingly, the dominant Tcb1 allele is found primarily in the weedy teosinte in corn fields, where it effectively blocks pollen flow from maize and may thus contribute to an incipient speciation process.<br>
<br>
Chromosome organization: surprises in the 'junk' DMA<br>
Maize genes, like those of rice and Arabidopsis, are generally compact with short introns and key promoter motifs located close to the coding region; a typical gene occupies 2-10 kb. But the maize genome is 20 times larger than that of Arabidopsis and 6 times larger than that of rice, as a result of the amplification of diverse families of retroelements. Individual or small clusters of maize genes are 'islands' of coding region in a vast sea of inactive transposons that occupy most of the genome; recombination is at least one or two orders of magnitude higher in the genes. And these genes are on the move: a published study of the 32 kb region around the bronze1 gene by Fu and Dooner in 2002 established that there are inbred lines with nine additional genes as well as inbred lines in which some of these genes are on other chromosomes or are entirely absent. To ask if the repetitive 'backbone' of the chromosomes was also rapidly changing, Jim Birchler (University of Missouri, Columbia, USA) reported the work of his postdoctoral fellow Akio Kato, who has developed a suite of fluorescent in situ hybridization (FISH) probes to detect moderately repetitive sequences that can distinguish each of the ten maize chromosomes in somatic cells. Comparing ten modern inbred lines of maize revealed that each line had a distinctive chromosome pattern as illustrated for chromosomes 2 and 6 in Figure 1. The repetitive component of the genome is, therefore, varying quantitatively (as shown by a range of signal strengths from specific probes) and perhaps qualitatively on an individual chromosome basis (shown by the absence of hybridization of individual probes).<br>
<br>
Allele dominance mediated by RNA interference<br>
The robust allelic series available for maize genes also permits the elucidation of the molecular basis for the dominant and recessive nature of particular alleles. Chalcone synthase catalyzes the first committed step in anthocyanin pigmentation; the C2 allele encodes active enzyme while c2 lines are deficient in this enzyme. Chris Della Vedova (University of Missouri, Columbia, USA) reported that C2-Idf is a dominant, complex, multi-copy allele found in Peruvian maize. C2-Idf suppresses anthocyanin pigmentation in leaf tissues of C2/C2-Idf heterozygotes (Figure 2). Full-length C2 transcripts are virtually absent from C2/C2-Idf lines, but transcription, as measured by run-on transcription assays, is nearly at wild-type levels. Abundant small RNAs of 21-23 nucleotides in length are derived from throughout the transcribed region whenever the C2-Idf allele is present, and their presence mirrors the decrease in pigmentation. Transiently infecting C2/C2-Idf leaves with plant viruses that encode suppressors of gene silencing restores pigment production in a pattern similar to that of viral spread without altering the intrinsic transcriptional rate. These results indicate that C2-Idf is inducing the post-transcriptional degradation of transcripts from the C2 allele.<br>
This talk and many others illustrated that the diversity of maize can be exploited by both molecular and population geneticists to answer fundamental questions about genetic interactions at the allele or karyotypic level within a plant and over short and long evolutionary time scales. The next harvest of maize results will be the 47th Annual Meeting to be held 10-13 March 2005 in Wisconsin, USA .<br>
<br>
<br>
<br>
<p><hr><p>

<b>PMC2784320</b><br>
<software>MethMarker</software>: user-friendly design and optimization of gene-specific DNA methylation assays<br>
A software workflow to translate known differentially methylated regions into clinical biomarkers<br>
<br>
Rationale<br>
Aberrant DNA methylation is a common event in many cancers [1,2]. Functionally, cancer-specific hypermethylation imposes condensed chromatin structure upon CpG islands that normally exhibit an open and transcriptionally competent chromatin structure [3]. This epigenetic alteration results in loss of expression at nearby genes, contributing to cancer development when tumor suppressor genes are affected [4].<br>
For many years, research in cancer epigenetics has focused on the use of CpG island hypermethylation events of certain genes as cancer biomarkers, with the aim of improving cancer treatment through more accurate diagnosis, prognosis and therapy selection [5,6]. Early diagnosis exploits the fact that CpG island hypermethylation of cancer-related genes is frequently detectable in early-stage tumors [7], for which surgical treatment can be highly effective. Prognosis of clinical outcome uses DNA hypermethylation events to infer whether or not a tumor is likely to constitute a major threat to the patient's health, which is particularly relevant for cancers that will kill only a subset of patients if left untreated (for example, prostate cancer). Therapy optimization makes use of DNA methylation differences between patient subgroups in order to select the most effective treatment, thus contributing to personalized cancer treatment.<br>
In spite of significant investment in genome-wide screening and subsequent validation studies, few DNA methylation biomarkers have been confirmed by clinical trials. This bottleneck in the process of translating basic research findings into the clinic is partially due to a discontinuity of methods between the discovery phase and the validation phase. The methods used most commonly in the discovery phase (such as tiling microarray and clonal bisulfite sequencing) are too time-consuming and expensive to be used in the clinical setting. Hence, candidate biomarkers have to be adapted to high sample-throughput methods such as MethyLight [8], bisulfite pyrosequencing [9-11], COBRA (combined bisulfite restriction analysis) [12] or bisulfite single nucleotide primer extension (SNuPE) [13,14]. To be effective, this adaptation step requires substantial bioinformatic optimization and validation.<br>
Based on our experience from a pilot study on the O6-methylguanine DNA methyltransferase (MGMT) gene [15], we have developed a systematic workflow for design, optimization and validation of DNA methylation biomarkers (reviewed in [16]). The six-step procedure outlined in Figure 1 starts from a preselected differentially methylated region (DMR), which may have been identified by genome-wide screening experiments or through a candidate gene approach. A typical example would be a CpG island that overlaps with the promoter region of a tumor suppressor gene. In the first step, this region is subjected to high-resolution analysis of DNA methylation in a small number of cases and controls (for example, by clonal bisulfite sequencing). These experimental data provide <software>MethMarker</software> with a representative map of methylation state within the DMR and inform all subsequent optimization steps. Second, using sets of expert rules, technically feasible DNA methylation assays are designed for each of six robust and cost-efficient experimental protocols (COBRA, bisulfite SNuPE, bisulfite pyrosequencing, MethyLight, methylation-specific polymerase chain reaction (MSP) and methylated DNA immunoprecipitation quantitative PCR (MeDIP-qPCR)). Third, the accuracy of all designed assays is computationally assessed, using the DNA methylation map derived in the first step. Fourth, the most promising candidate biomarkers are statistically optimized for maximum discrimination between cases and controls. Fifth, to reduce the risk that candidate biomarkers subsequently fail due to technical problems or lack of robustness, all high-scoring assays are validated with respect to their susceptibility to experimental noise, measurement errors and unknown single nucleotide polymorphisms. Sixth, the most promising assay is selected, experimentally tested and further optimized based on the outcome of the experimental validation. After completion of these six steps, the candidate biomarker is ready for application and further validation in clinical studies.<br>
Apart from two key experimental analyses - the generation of high-resolution DNA methylation data in step one and assay validation in step six - this workflow is essentially bioinformatic in nature. We developed the <software>MethMarker</software> software as a user-friendly implementation of the bioinformatic steps, including automatic assay design for six widely used experimental methods (COBRA, bisulfite SNuPE, bisulfite pyrosequencing, MethyLight, MSP and MeDIP-qPCR) and computational biomarker optimization. <software>MethMarker</software> integrates well with existing bioinformatic tools for analyzing DNA methylation (reviewed in [17]): epigenome analysis tools such as <software>Galaxy</software> [18] and <software>EpiGRAPH</software> [19] can be used to select promising DMRs for optimization with <software>MethMarker</software>, and high-resolution DNA methylation data can be imported directly from three widely used software packages, <software>BiQ Analyzer</software> [20], <software>QUMA</software> [21] and <software>EpiTYPER</software> [22], as well as from custom tables. Finally, optimized biomarkers can be exported in the standardized <fileFormat>predictive model markup language</fileFormat> (<fileFormat>PMML</fileFormat>) format [23], which facilitates interoperation with molecular diagnostics software. A typical screenshot of <software>MethMarker</software> is displayed in Figure 2.<br>
<br>
Application<br>
To illustrate the biomarker development workflow outlined in Figure 1 and to demonstrate the practical use of <software>MethMarker</software>, we describe its application to the MGMT gene promoter, highlighting important decisions, necessary validation experiments and potential stumbling blocks. The raw data for this case study are taken from a recent experimental study [15] and are included as a demonstration dataset in the <software>MethMarker</software> download package.<br>
The MGMT gene encodes a DNA repair protein, which removes alkyl groups from the O6-position of guanine, therefore protecting the DNA from accumulating excessive damage [24]. It has been shown in a number of studies (see [25] and references therein) that hypermethylation of the MGMT promoter is a frequent event in various cancers (that is, is relevant for diagnosis), that it is associated with decreased survival if the cancer is untreated (that is, is relevant for prognosis), and that it renders tumors susceptible to alkylating drugs such as temozolomide (that is, is also relevant for therapy optimization). However, until recently no assay for measuring MGMT promoter methylation had been available that was robust enough for routine clinical use and fully compatible with DNA extracted from formalin-fixed, paraffin-embedded samples [26].<br>
For these reasons, the promoter of the MGMT gene is an excellent target region for demonstrating the systematic development of a DNA methylation biomarker, such that the resulting assay is accurate, robust and cost-efficient enough for clinical use. To start with, we obtain the genomic DNA sequence of the MGMT promoter region from the <database>UCSC Genome Browser</database> [27]. We also obtain 22 glioblastoma samples, a subset of them showing MGMT promoter methylation, as well as three normal brain samples for use as healthy tissue controls. Next, bisulfite-specific PCR primers are designed (manually or using a software tool such as <software>Methyl Primer Express</software> [28]), and clonal bisulfite sequencing is performed on DNA from all samples according to a widely used protocol [29]. The sequencing data are processed and quality controlled with <software>BiQ Analyzer</software> [20], resulting in 25 high-resolution DNA methylation profiles that are used as training samples. (Note that it is usually sufficient to have five to ten training samples per class to guide the optimization step. In our case, however, it was not clear a priori how many of the tumor samples would turn out to belong to the methylated cases or to the unmethylated controls, respectively. Hence, a relatively large number of samples were subjected to clonal bisulfite sequencing.)<br>
Next, the genome sequence of the target region, the corresponding primer sequences and the <software>BiQ-Analyzer</software> processed DNA methylation profiles are imported into <software>MethMarker</software>. The software tool automatically identifies the correct location of the MGMT promoter on human chromosome 10, visualizes the position of the first exon and aligns the DNA methylation profiles of all 25 training samples (Figure 2). We let <software>MethMarker</software> classify the training samples into cases and controls, using hierarchical clustering of the DNA methylation profiles. Consistent with previous observations, we obtain a large cluster of samples in which the MGMT promoter is unmethylated and a smaller cluster consisting of tumor samples with methylated MGMT promoters. The former cluster - which we will refer to as 'controls' - contains the normal brain samples and a subset of tumors that are likely to be resistant to alkylating agents used for chemotherapy. The latter cluster ('cases') comprises tumor samples only, presumably those that are susceptible for chemotherapy using alkylating drugs such as temozolomide [30].<br>
Based on this classification, our goal is to find a DNA methylation assay (or a combination of several assays) that provides accurate, robust and cost-efficient separation between cases and controls. First, we let <software>MethMarker</software> design all feasible DNA methylation assays for the target region, using COBRA, bisulfite SNuPE, bisulfite pyrosequencing, MethyLight and MeDIP-qPCR. We chose to exclude MSP because several MSP-based assays for MGMT promoter hypermethylation are already available [26] and because MSP-based assays do not always work well on formalin-fixed, paraffin-embedded samples [15]. Next, we let <software>MethMarker</software> score the individual assays in terms of their correlation with the overall DNA methylation level in each of the training samples (Additional data file 1). A Pearson correlation coefficient above 0.9 and a Spearman correlation coefficient above 0.8 indicate a highly accurate and predictive assay. Even when a single CpG site already provides a highly accurate measurement - as is the case here - it is highly recommended to use a combination of at least three to four CpG sites in order to increase robustness of the DNA methylation assay in the presence of experimental noise and rare sequence polymorphisms. To that end, <software>MethMarker</software> identifies the optimal combinations of DNA methylation assays for each method, again ranked by their correlation with the overall DNA methylation level in each of the training samples (Additional data file 1).<br>
From the resulting list, we select several assay combinations that appear to provide a suitable balance between accuracy, robustness and cost (higher robustness is usually achieved by including more CpG sites, which makes the candidate biomarker more expensive to use). For each of these assay combinations, we let <software>MethMarker</software> optimize logistic regression models that predict whether a sample belongs to the cases or to the controls (Figure 3). During this step, weights are learned for the individual assays in order to maximize the classification accuracy of the candidate biomarker. <software>MethMarker</software> benchmarks the candidate biomarkers in terms of accuracy, correlation, specificity and sensitivity. Additionally, the biomarkers' robustness is assessed by comparing false positive and false negative rates under increasing error rate, by simulating noisy measurement data. This step accounts for the fact that not all error sources may be well-represented in the training data. For example, COBRA, bisulfite SNuPE and bisulfite pyrosequencing are sensitive to rare inherited C-to-T single nucleotide polymorphisms at the assayed CpGs, and MSP as well as MethyLight can give rise to erroneous measurements if the DNA methylation profile in the target region only partially matches with the designed probe (see Mikeska et al. [15] and Bock et al. [20] for a more in-depth discussion of potential error sources).<br>
For each candidate biomarker, <software>MethMarker</software> also calculates an extensive performance evaluation summary (Figure 4). We use the results from this window to compare how well several top-scoring candidate biomarkers separate between the methylated cases and unmethylated controls. Also, we test the robustness of each candidate biomarker by artificially introducing noise and observing how much noise it can tolerate until the first classification errors start to appear. As a quintessence of all performance evaluations of <software>MethMarker</software>, we conclude that the following two candidate biomarkers are most suitable for assessing promoter hypermethylation of the MGMT gene in routine clinical use: the COBRA biomarker comprising CpG sites 5/6 and 18, utilizing the Hpy99I and HpyCH4III restriction endonucleases (r = 0.985), and the bisulfite pyrosequencing biomarker comprising CpG sites 13, 18 and 20 (r = 0.990). Both biomarkers achieve 100% test set accuracy during leave-one-out cross-validation. Compared to the biomarkers that we previously established for the same dataset [15], the biomarkers identified by <software>MethMarker</software> achieve an identical accuracy and score marginally higher in terms of correlation and robustness (data not shown). Nevertheless, we recommend that practical studies of MGMT promoter methylation continue using the previously published biomarkers [15] because they have been validated experimentally, while the two <software>MethMarker</software>-derived biomarkers reported here have not been tested on clinical samples.<br>
Having completed the design, optimization and computational validation of candidate biomarker DNA methylation assay for the MGMT promoter, two key steps remain: experimental assay validation and experimental biomarker validation. First, it is essential to make sure that the DNA methylation assays included in the selected biomarker work well in the lab and result in roughly the same DNA methylation measurements as predicted based on the high-resolution DNA methylation profiles. To that end, the assays are applied to DNA from the training samples, and each assay's empirical measurement value is compared with the simulated measurement value that <software>MethMarker</software> calculated from the high-resolution profiles. Assays showing low correlation or high deviation should be rejected from practical use as biomarkers. Second, the most important step for any new DNA methylation biomarker is to validate its sensitivity, specificity and practical utility in a large number of patients, both by retrospective studies based on archival material with known clinical history and in prospective clinical trials. While several clinical trials have already confirmed the effect of MGMT hypermethylation on chemotherapy resistance in gliomas [31] and glioblastomas [30,32], the <software>MethMarker</software>-optimized biomarker may facilitate the clinical confirmation of MGMT's predictive role in other cancers.<br>
<br>
Conclusions<br>
Recent advances in genome-wide DNA methylation mapping have provided researchers with rapid and cost-efficient ways to contribute to the ever-growing list of genomic regions reported as differentially methylated in specific cancers and/or patient subgroups. However, a comparable advance for the efficient conversion of DMRs into clinical biomarkers is lacking. Thus, the rate with which new DNA methylation biomarkers are tested and confirmed in clinical trials has remained disappointingly low. While it is inevitable that a large percentage of candidate biomarkers will fail in clinical trials (either because they are not reproducible in different patient cohorts or because their sensitivity and specificity are insufficient for practical use), a more systematic approach to epigenetic biomarker development could help discard many of these unsuccessful candidates early and at low cost. Conversely, careful selection and optimization of candidate biomarkers can reduce the risk of losing effective biomarkers due to contingencies of the validation process, such as accidental selection of DNA methylation assays that measure highly noisy CpG positions in a promoter region that would otherwise provide reliable classification. The workflow described in this paper provides a starting point toward a more systematic way of transforming disease-specific DMRs into robust and cost-efficient clinical biomarkers. The <software>MethMarker</software> software was developed to facilitate the implementation of this workflow. To enable further refinement and adaptation to local requirements, we are happy to share <software>MethMarker</software>'s source code with interested researchers.<br>
<br>
Materials and methods<br>
<software>MethMarker</software> is implemented in Java (version 1.5 or later required). It is platform-independent and can be launched directly from within a web browser. The software comes with a case-study tutorial demonstrating the design, optimization and validation of a DNA methylation biomarker based on the MGMT gene. <software>MethMarker</software>'s user interface reflects the workflow for biomarker design, optimization and validation outlined in Figure 1.<br>
Step 1: data import<br>
As the first step, the DMR of interest is imported. <software>MethMarker</software> supports several sequence formats, including <fileFormat>FASTA</fileFormat>, <fileFormat>GenBank</fileFormat> and <fileFormat>EMBL</fileFormat>. Typical regions of interest include the promoters of tumor suppressor genes and CpG islands that exhibit cancer-specific hypermethylation. However, <software>MethMarker</software> imposes no restrictions on the type of region to be analyzed. <software>MethMarker</software> can thus be applied not only to human cancers, but more generally to epigenotyping in all kinds of organisms that exhibit CpG dinucleotide methylation.<br>
High-resolution DNA methylation profiles for a subset of cases and controls are crucial for <software>MethMarker</software>'s optimization process, as they provide the training set on which all candidate biomarkers are optimized and computationally validated. These profiles are usually derived by clonal bisulfite sequencing [33] or mass spectrometry and preprocessed with appropriate tools. <software>MethMarker</software> can directly import DNA methylation profiles from files generated with <software>BiQ Analyzer</software> [20], <software>QUMA</software> [21] and <software>EpiTYPER</software> [22], and it is easy to convert DNA methylation data from a different source into a format that can be read by <software>MethMarker</software>.<br>
On completion of data import, <software>MethMarker</software> displays a high-resolution DNA methylation profile of the region of interest, visualized as lollipop diagrams or as methylation propensity diagrams. Internally, <software>MethMarker</software> uses Needleman-Wunsch sequence alignment [34] in order to correct for incomplete overlap between the target region and the DNA methylation profiles. It is thus possible to tile a large target region with several bisulfite sequencing amplicons.<br>
Optionally, <software>MethMarker</software> can annotate the region with transcription start site and exon positions retrieved from the <database>UCSC Genome Browser</database> [27]. To that end, <software>MethMarker</software> performs an automatic <software>BLAT</software> search on the <database>UCSC Genome Browser</database> website, obtains the genomic coordinates of the region and retrieves exon information for overlapping RefGene genes from the <database>UCSC Table Browser</database>. Data on single nucleotide polymorphisms are acquired in the same way, enabling <software>MethMarker</software> to avoid polymorphic sites when designing DNA methylation assays. All annotation data can be manually revised and amended.<br>
<br>
Step 2: design of DNA methylation assays<br>
<software>MethMarker</software> implements automatic assay design for six experimental methods commonly used for DNA methylation analysis: COBRA, bisulfite SNuPE, bisulfite pyrosequencing, MethyLight, MSP and MeDIP-qPCR. The first five methods utilize bisulfite treatment of genomic DNA to detect DNA methylation indirectly. However, they differ in the way they interrogate the amount of DNA methylation, leading to specific experimental constraints that limit the application of each method to assaying a subset of CpG positions. The sixth method, MeDIP-qPCR, uses an antibody-based approach to enrich for methylated genomic DNA, which leads to quite different experimental constraints [35]. For all methods, assay design rules were developed, reviewed by domain experts and implemented in <software>MethMarker</software>, as described in more detail in the <software>MethMarker</software> assay design dialogue. However, it is recommended that all primers designed with <software>MethMarker</software> are reviewed by the experimenter before ordering, to exclude problems such as hairpins, self-dimers and cross-dimers, which <software>MethMarker</software> does not automatically check for.<br>
All automatically designed DNA methylation assays can be visualized, revised or excluded by the user, for example, based on results of previous experiments. Furthermore, <software>MethMarker</software> allows users to define and incorporate custom assays, which enables the software to include experimental methods that are not directly supported.<br>
<br>
Step 3: scoring of DNA methylation assays<br>
Based on the samples for which high-resolution DNA methylation profiles are available (see step 1), <software>MethMarker</software> scores all DNA methylation assays in terms of their correlation with the overall level of DNA methylation in each sample. The measurement values of the DNA methylation assays are calculated directly from the high-resolution DNA methylation profiles, using a set of method-specific rules. For COBRA, bisulfite SNuPE and bisulfite pyrosequencing, the measurement value is calculated simply as the average DNA methylation level of the assayed CpG site(s), based on the high-resolution DNA methylation profiles of the respective sample. For MSP, MethyLight and MeDIP-qPCR, the measurement value is calculated as the percentage of individual clones in which all participating CpG sites are simultaneously methylated. To better resemble real PCR conditions, for MSP and MethyLight a single CpG position is allowed to have an incorrect methylation value. While simulated measurements cannot replace experimental validation of the resulting DNA methylation assays (see [36] for a discussion of the limitations of simulating DNA methylation measurements in silico), they provide a suitable indication for identifying the most predictive DNA methylation assays to be included in the optimization step.<br>
<br>
Step 4: biomarker optimization<br>
From the list of DNA methylation assays, ranked by their correlation with the overall DNA methylation levels of the training samples, the user can select a subset for biomarker optimization. <software>MethMarker</software> then scores all possible combinations of the selected DNA methylation assays and again assesses the correlation with the overall DNA methylation levels of the training samples. To allow for fair comparison between assay sets of different sizes, no weight fitting is performed at this stage. Rather, the score value of each combination is calculated as the mean measurement value of all contributing DNA methylation assays. The results of this comparison are listed in the order of decreasing correlation coefficients, and the user can select a subset of the most highly scoring combinations of DNA methylation assays for optimization and computational validation as candidate biomarkers, a procedure that is performed as follows.<br>
First, the training samples are classified into cases and controls. This classification can be performed based on known sample information (for example, tumor samples versus normal tissue annotation) or based on the DNA methylation profiles themselves, using one of the following methods: a fixed threshold on the average DNA methylation level, hierarchical clustering, or K-means clustering with K = 2. In all cases, the DNA methylation profiles in the subset with the higher average methylation levels are labeled as methylated 'cases' and the remaining profiles are labeled as unmethylated 'controls'.<br>
Second, logistic regression is used to optimize the weight with which the individual measurements contribute to the overall biomarker score, accounting for the fact that different CpGs vary in their predictiveness of the overall level of DNA methylation. Internally, <software>MethMarker</software> uses the <software>WEKA</software> package [37] to train a logistic regression model for each candidate biomarker, classifying the training samples into cases versus controls based on simulated methylation measurements for all contributing CpGs.<br>
Third, the predictiveness of the logistic regression models is validated by leave-one-out cross-validation - that is, the logistic regression models are repeatedly trained on all but one training samples and their prediction performance is assessed on the remaining sample. The results of the optimization step, including a cross-validation-based estimate of the prediction performance on new data, are displayed in the biomarker summary window (Figure 4).<br>
<br>
Step 5: validation of DNA methylation biomarkers<br>
While the results of the leave-one-out cross-validation (step 4) already provide an important selection criterion for identifying the most suitable DNA methylation biomarkers, they do not account for potential errors and experimental problems that can occur during practical use. <software>MethMarker</software> therefore provides an additional validation step, which assesses the robustness of each candidate biomarker toward noisy data, sequencing errors and unknown single nucleotide polymorphisms. In this step, the optimal logistic regression model is re-applied to all samples for which high-resolution DNA methylation profiles are available (this can include samples that were not taken into account in the training phase - for example, because they constitute outliers or borderline cases), and the biomarker's prediction confidence for a given sample is plotted against its mean DNA methylation level, as calculated from the DNA methylation profiles. It is thus possible to visually assess how well each candidate biomarker separates between the (methylated) cases and (unmethylated) controls. Furthermore, <software>MethMarker</software> assesses the robustness toward erroneous data - such as sequencing errors or unknown single nucleotide polymorphisms - by randomly changing the DNA methylation measurement of a subset of CpGs. The error rate is varied over a wide range, and the impact on the prediction accuracy is visualized in the biomarker summary window (Figure 4), enabling the user to assess whether or not a specific candidate biomarker is sufficiently robust for clinical use.<br>
<br>
Step 6: application of DNA methylation biomarkers<br>
Based on the results of the computational assessment, the user selects a few of the most promising biomarkers for experimental validation, performs the necessary DNA methylation assays on DNA from the training samples and uploads the results into <software>MethMarker</software>. By comparison between the simulated and actual measurements, <software>MethMarker</software> can evaluate the reliability of each candidate biomarker under routine experimental conditions and re-train its logistic regression models accordingly (for example, down-weighting the contribution of a CpG whose DNA methylation assay exhibits a high level of experimental noise). This experimental validation step is important because it corrects for any deviations from the theoretically optimal measurement conditions that underlie the computational simulation of measurement values.<br>
When the optimization and validation steps are completed and the user is satisfied with the overall performance, one or more candidate biomarkers are typically selected for further development. <software>MethMarker</software> provides two ways of facilitating the steps toward comprehensive clinical testing and widespread practical use. First, <software>MethMarker</software> can generate a comprehensive <fileFormat>PDF</fileFormat> report describing the key properties of a selected biomarker. This report includes the final sample classification formula as well as a summary of the accuracy and robustness assessment. Based on this file, it is straightforward to apply the biomarker assay to new data, requiring no statistical or bioinformatic tools beyond a pocket calculator. Second, a selected biomarker can be exported in a standardized data format, <fileFormat>PMML</fileFormat>, which is supported by several statistics packages and can be imported into diagnostics software. <fileFormat>PMML</fileFormat> has been developed by the Data Mining Group [23] to facilitate data exchange between developers and users of classification and regression models. All classifiers created with <software>MethMarker</software> fulfill the <fileFormat>PMML</fileFormat> 3.2 standard (see Additional data file 2 for illustration). Third, <software>MethMarker</software> supports multi-center biomarker validation studies. To that end, the <fileFormat>PDF</fileFormat> and <fileFormat>PMML</fileFormat> documentation files of the selected biomarker are distributed to all participating centers; each center then performs the necessary DNA methylation assays for all local samples, loads the <fileFormat>PMML</fileFormat> file and the measurement values into <software>MethMarker</software> and obtains the biomarker result for each of their samples; finally, the measurement values from all centers as well as the corresponding clinical data are combined, loaded into <software>MethMarker</software> and a global assessment of biomarker performance is obtained. If the performance is not satisfactory, the entire process can be reiterated and the biomarker re-optimized based on the data obtained in the previous round of validations.<br>
<br>
<br>
Abbreviations<br>
COBRA: combined bisulfite restriction analysis; DMR: differentially methylated region; MeDIP-qPCR: methylated DNA immunoprecipitation quantitative PCR; MGMT: O6-methylguanine DNA methyltransferase; MSP: methylation-specific polymerase chain reaction; PMML: predictive model markup language; SNuPE: single-nucleotide primer extension.<br>
<br>
Competing interests<br>
The authors declare that they have no competing interests.<br>
<br>
Authors' contributions<br>
CB initiated the project and conceptualized workflow and software. PS designed and implemented <software>MethMarker</software>, developed the case study tutorial, set up the website and drafted the paper. TM devised the assay design rules and contributed his experience with COBRA, bisulfite SNuPE, bisulfite Pyrosequencing, MSP, MethyLight and MeDIP-qPCR. He also provided experimental data and performed extensive beta testing. AW provided experimental data. TL contributed advice and ideas throughout the project. All authors were involved in the writing of the paper.<br>
<br>
Additional data files<br>
The following additional data are available with the online version of this paper: a screenshot of <software>MethMarker</software>'s performance ranking of DNA methylation assays and candidate biomarkers (Additional data file 1); the <fileFormat>XML</fileFormat>-based <fileFormat>PMML</fileFormat> model that <software>MethMarker</software> uses for exporting, importing and storing candidate biomarkers (Additional data file 2).<br>
<br>
Supplementary Material<br>
<br>
<br>
<br>
<p><hr><p>

</body></html>
